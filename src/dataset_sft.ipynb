{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import random\n",
    "import ollama\n",
    "\n",
    "# 心境障碍\n",
    "# patient_info = pd.read_excel(r\"D:\\work\\code\\psychgpt\\data\\患者信息-0422.xlsx\")\n",
    "# first_record = pd.read_excel(r\"D:\\work\\code\\psychgpt\\data\\首程.xlsx\")\n",
    "# case_record = pd.read_excel(r\"D:\\work\\code\\psychgpt\\data\\病程.xlsx\")\n",
    "\n",
    "# 精神分裂症\n",
    "patient_info = pd.read_excel(r\"D:\\work\\data_process\\F20-F29\\F20-F29基本信息.xlsx\")\n",
    "first_record = pd.read_excel(r\"D:\\work\\data_process\\F20-F29\\F20-F29首程.xlsx\")\n",
    "case_record = pd.read_excel(r\"D:\\work\\data_process\\F20-F29\\F20-F29病程.xlsx\")\n",
    "\n",
    "# 精分\n",
    "# case_record = pd.read_excel(r'D:\\work\\code\\psychgpt_benchmark\\domain\\2023主诊断精神分裂症随机100人-病程.xlsx')\n",
    "# patient_info = pd.read_excel(r'D:\\work\\code\\psychgpt_benchmark\\domain\\2023主诊断精神分裂症随机100人.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集统计\n",
    "drugs_kyy_kjsb = [\n",
    "    '利培酮',\n",
    "    '去甲文拉法辛',\n",
    "    '阿戈美拉汀',\n",
    "    '阿立哌唑',\n",
    "    '阿米替林',\n",
    "    '艾司西酞普兰',\n",
    "    '氨磺必利',\n",
    "    '安非他酮',\n",
    "    '奥氮平',\n",
    "    '奥沙西泮',\n",
    "    '丙戊酸',\n",
    "    '地西泮',\n",
    "    '度洛西汀',\n",
    "    '多虑平',\n",
    "    '多奈哌齐',\n",
    "    '奋乃静',\n",
    "    '氟奋乃静',\n",
    "    '氟伏沙明',\n",
    "    '氟西汀',\n",
    "    '氟哌啶醇',\n",
    "    '伏硫西汀',\n",
    "    '卡马西平',\n",
    "    '拉莫三嗪',\n",
    "    '鲁拉西酮',\n",
    "    '氯丙嗪',\n",
    "    '氯氮平',\n",
    "    '氯米帕明',\n",
    "    '美金刚',\n",
    "    '米安色林',\n",
    "    '米氮平',\n",
    "    '米那普仑',\n",
    "    '帕罗西汀',\n",
    "    '齐拉西酮',\n",
    "    '曲唑酮',\n",
    "    '舍曲林',\n",
    "    '舒必利',\n",
    "    '喹硫平',\n",
    "    '文拉法辛',\n",
    "    '西酞普兰',\n",
    "    '硝西泮',\n",
    "    '唑吡坦',\n",
    "    '地昔帕明',\n",
    "    '去甲替林',\n",
    "    '丙米嗪',\n",
    "    '多塞平',\n",
    "    '马普替林',\n",
    "    '帕利哌酮',\n",
    "    '咪达唑仑',\n",
    "    '劳拉西泮',\n",
    "    '碳酸锂',\n",
    "]\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 191\u001b[0m\n\u001b[0;32m    188\u001b[0m orgnized_record \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# 提取患者病情进展字段和医生诊疗决策字段\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     patient_progress \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m患者病情进展：(.*?)医生诊疗决策\u001b[39m\u001b[38;5;124m'\u001b[39m, orgnized_record)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[24], line 191\u001b[0m\n\u001b[0;32m    188\u001b[0m orgnized_record \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# 提取患者病情进展字段和医生诊疗决策字段\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     patient_progress \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m患者病情进展：(.*?)医生诊疗决策\u001b[39m\u001b[38;5;124m'\u001b[39m, orgnized_record)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\15113\\anaconda3\\envs\\anding\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\15113\\anaconda3\\envs\\anding\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "drugs_kyy_kjsb = [\n",
    "    '利培酮',\n",
    "    '去甲文拉法辛',\n",
    "    '阿戈美拉汀',\n",
    "    '阿立哌唑',\n",
    "    '阿米替林',\n",
    "    '艾司西酞普兰',\n",
    "    '氨磺必利',\n",
    "    '安非他酮',\n",
    "    '奥氮平',\n",
    "    '奥沙西泮',\n",
    "    '丙戊酸',\n",
    "    '地西泮',\n",
    "    '度洛西汀',\n",
    "    '多虑平',\n",
    "    '多奈哌齐',\n",
    "    '奋乃静',\n",
    "    '氟奋乃静',\n",
    "    '氟伏沙明',\n",
    "    '氟西汀',\n",
    "    '氟哌啶醇',\n",
    "    '伏硫西汀',\n",
    "    '卡马西平',\n",
    "    '拉莫三嗪',\n",
    "    '鲁拉西酮',\n",
    "    '氯丙嗪',\n",
    "    '氯氮平',\n",
    "    '氯米帕明',\n",
    "    '美金刚',\n",
    "    '米安色林',\n",
    "    '米氮平',\n",
    "    '米那普仑',\n",
    "    '帕罗西汀',\n",
    "    '齐拉西酮',\n",
    "    '曲唑酮',\n",
    "    '舍曲林',\n",
    "    '舒必利',\n",
    "    '喹硫平',\n",
    "    '文拉法辛',\n",
    "    '西酞普兰',\n",
    "    '硝西泮',\n",
    "    '唑吡坦',\n",
    "    '地昔帕明',\n",
    "    '去甲替林',\n",
    "    '丙米嗪',\n",
    "    '多塞平',\n",
    "    '马普替林',\n",
    "    '帕利哌酮',\n",
    "    '咪达唑仑',\n",
    "    '劳拉西泮',\n",
    "    '碳酸锂',\n",
    "]\n",
    "\n",
    "conversations_1 = []\n",
    "conversations_2 = []\n",
    "conversations_3 = []\n",
    "conversations_4 = []\n",
    "\n",
    "cases_missing_sth = []\n",
    "\n",
    "for ipid in patient_info['IPID'].unique():\n",
    "    try:\n",
    "        patient = patient_info[patient_info['IPID']==ipid]\n",
    "        first = first_record[first_record['SYXH']==ipid]['YZTL'].iloc[0]\n",
    "        records = case_record[case_record['IPID']==ipid]\n",
    "    except:\n",
    "        print('Something missing on {}'.format(ipid))\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # 准备输入字段\n",
    "    senior_record = pd.concat([records[records['BL_TYPE']=='主任医师首次查房记录'], \n",
    "                               records[records['BL_TYPE']=='副主任医师首次查房记录']], axis=0, ignore_index=True)\n",
    "    senior_record_content = senior_record['YZTL'].to_list()\n",
    "    if len(senior_record_content) == 0:\n",
    "        junior_record = records[records['BL_TYPE']=='主治医师首次查房记录']\n",
    "        junior_record_content = junior_record['YZTL'].to_list()\n",
    "        if len(junior_record_content) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            senior_record_content = junior_record_content\n",
    "    senior_record_content.sort()\n",
    "    content = senior_record_content[0]\n",
    "    try:\n",
    "        mental_exam = re.search(r'精神检查：(.*?)\\n', content, re.S).group(1).strip().split('精神检查')[1]\n",
    "    except:\n",
    "        mental_exam = re.search(r'精神检查：(.*?)\\n', content, re.S).group(1).strip().split('精神检查')[0]\n",
    "    try:\n",
    "        base = '患者{}性，{}岁。\\n'.format(patient['性别'].iloc[0], patient['年龄'].iloc[0])\n",
    "        current_his = patient['现病史'].iloc[0] + '\\n'\n",
    "        brief_his = '现病史：' + re.search(r'4.临床表现：(.*?)5.既往史：', first, re.S).group(1).strip() + '\\n' \n",
    "        # brief_his = '简要病史：' + re.search(r'4.临床表现：(.*?)5.既往史：', first, re.S).group(1).strip() + '\\n'    \n",
    "        past_his = '既往史：' + re.search(r'5.既往史：(.*?)6.家族史：', first, re.S).group(1).strip() + '\\n' \n",
    "        family_his = '家族史：' + re.search(r'6.家族史：(.*?)7.查体及辅助检查：', first, re.S).group(1).strip() + '\\n' \n",
    "        exam = '查体，辅助检查及精神检查：' + re.search(r'7.查体及辅助检查：(.*?)拟诊讨论：', first, re.S).group(1).strip() + mental_exam + '\\n' \n",
    "        date_in = '入院日期：{}年{}月{}日'.format(str(patient['入院日期'].iloc[0])[:4], str(patient['入院日期'].iloc[0])[4:6], str(patient['入院日期'].iloc[0])[6:8])\n",
    "    except:\n",
    "        print('Something missing on {}'.format(ipid))\n",
    "        continue\n",
    "    \n",
    "    # if random.random() > 0.7:\n",
    "    #     input_info = base + brief_his + past_his + family_his + exam + date_in\n",
    "    # else:\n",
    "    #     input_info = base + current_his + past_his + family_his + exam + date_in\n",
    "    \n",
    "    input_info = base + current_his + past_his + family_his + exam + date_in\n",
    "    \n",
    "    # 准备输出字段-task1\n",
    "    # try:\n",
    "    #     zs = '主诉：{}\\n'.format(re.search(r'主因“(.*?)”入院', first, re.S).group(1).strip())\n",
    "    # except:\n",
    "    #     zs = first_record[first_record['SYXH']==ipid]['ZS'].iloc[0]\n",
    "    \n",
    "    # summary_0 = '0.简要病史：' + brief_his + '\\n'\n",
    "    # summary_1 = '1.病程标准：' + re.search(r'1.病程标准：(.*?)2.症状学标准', first, re.S).group(1).strip() + '\\n'\n",
    "    # summary_2 = '2.症状学标准：' + re.search(r'2.症状学标准：(.*?)3.严重程度标准', first, re.S).group(1).strip() + '\\n'\n",
    "    # summary_3 = '3.严重程度标准：' + re.search(r'3.严重程度标准：(.*?)4.排除标准', first, re.S).group(1).strip() + '\\n'\n",
    "    # summary_4 = '4.排除标准：' + re.search(r'4.排除标准：(.*?)5.入院印象', first, re.S).group(1).strip() + '\\n'\n",
    "    # summary = '病例特点：{}'.format(summary_0 + summary_1 + summary_2 + summary_3 + summary_4)\n",
    "\n",
    "    # output_task1 = zs + summary\n",
    "    \n",
    "    # 准备输出字段-task2\n",
    "    # diag_primary = '主要诊断：{}\\n'.format(patient['出院主要诊断'].iloc[0])\n",
    "    # other_name = patient['出院其他诊断'].iloc[0]\n",
    "    # other_code = patient['出院其他诊断ICD'].iloc[0]\n",
    "    # other_mental_disease = \"\"\n",
    "    # if 'F' in str(other_code):\n",
    "    #     other_list = other_code.split(',')\n",
    "    #     for idx, other_disease in enumerate(other_list):\n",
    "    #         if 'F' in str(other_disease):\n",
    "    #             other_mental_disease += other_name.split(',')[idx]\n",
    "    #             other_mental_disease += ';'\n",
    "    #     diag_other = '精神科共病诊断：{}\\n'.format(other_mental_disease)\n",
    "    # else:\n",
    "    #     diag_other = '精神科共病诊断：无\\n'\n",
    "    \n",
    "    # output_task2 = diag_primary + diag_other\n",
    "    \n",
    "    # primary_diag = patient['出院主要诊断'].iloc[0]\n",
    "    # try:\n",
    "    #     clean_analysis = re.search(r'对诊断及鉴别诊断分析：(.*?)诊疗原则及处理计划', content, re.S).group(1).strip()\n",
    "    # except:\n",
    "    #     print(content)\n",
    "    #     continue\n",
    "    # differential = f'主要诊断：{primary_diag}。' + '诊断及鉴别诊断分析：{}'.format(\"，\".join(re.split(r'[,:，：]', clean_analysis)[1:]))\n",
    "    # if '鉴别' not in differential:\n",
    "    #     differential += '鉴别诊断：' + re.search(r'鉴别诊断：(.*?)诊疗计划', first, re.S).group(1).strip() + '\\n' \n",
    "    # output_task2 = differential\n",
    "    \n",
    "    \n",
    "    # 准备输出字段-task3\n",
    "    # senior_record = pd.concat([records[records['BL_TYPE']=='主任医师首次查房记录'], \n",
    "    #                            records[records['BL_TYPE']=='副主任医师首次查房记录']], axis=0, ignore_index=True)\n",
    "    # senior_record_content = senior_record['YZTL'].to_list()\n",
    "    # if len(senior_record_content) == 0:\n",
    "    #     junior_record = records[records['BL_TYPE']=='主治医师首次查房记录']\n",
    "    #     junior_record_content = junior_record['YZTL'].to_list()\n",
    "    #     if len(junior_record_content) == 0:\n",
    "    #         continue\n",
    "    #     else:\n",
    "    #         senior_record_content = junior_record_content\n",
    "    # senior_record_content.sort()\n",
    "    # content = senior_record_content[0]\n",
    "    # mental_exam = re.search(r'精神检查：(.*?)对诊断及鉴别诊断分析', content, re.S).group(1).strip()\n",
    "    \n",
    "    # try:\n",
    "    #     output_task3 = '诊疗计划：' + re.search(r'诊疗计划：(.*?)医师签名', first, re.S).group(1).strip() + '\\n'\n",
    "    # except:\n",
    "    #     print(first)\n",
    "    #     continue\n",
    "    \n",
    "    \n",
    "    # 准备输出字段-task4\n",
    "    records = records.sort_values(by='YZTL')\n",
    "    # prompt = \"请从以下患者病程记录中，分别提取出客观的患者病情进展(包括患者的临床表现，查体，精神检查，辅助检查等结果)和主观的医生分析及诊疗决策（包括对患者检查结果的分析，对患者的诊断，治疗计划的制定等内容）。输出格式为：患者病情进展：xxx。医生诊疗决策：xxx。不要输出其他内容。\"\n",
    "    \n",
    "    prompt = \"\"\"\n",
    "    你是一个精通大语言模型开发的精神科医生，现在要将精神科患者数据处理成结构化数据来训练大语言模型。\n",
    "    请从以下患者病程记录中，精确提取并区分两部分内容：\n",
    "\n",
    "    ###患者病情进展：包括客观记录的患者临床表现（如症状、查体结果、精神检查结果、辅助检查数据等）。\n",
    "    \n",
    "    ###医生诊疗决策：包括主观分析和决策内容（如对检查结果的分析、诊断结论、治疗计划的制定等）。\n",
    "    \n",
    "    请严格按照以下输出格式组织结果：\n",
    "\n",
    "    患者病情进展：xxx\n",
    "    医生诊疗决策：xxx\n",
    "    \n",
    "    注意事项：\n",
    "    仅提取相关信息，不要输出与任务无关的内容或注释。\n",
    "    确保信息分类准确，避免混淆客观病情与主观诊疗内容。\n",
    "    \"\"\"\n",
    "    \n",
    "    for index, record in records.iterrows():\n",
    "        record_type = record['BL_TYPE']\n",
    "        record_content = record['YZTL']\n",
    "        \n",
    "        response = ollama.chat(model='qwen2', messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f\"{prompt}患者病程记录：{record_content}\",\n",
    "        },\n",
    "        ])\n",
    "        orgnized_record = response['message']['content']\n",
    "        \n",
    "        # 提取患者病情进展字段和医生诊疗决策字段\n",
    "        try:\n",
    "            patient_progress = re.search(r'患者病情进展：(.*?)医生诊疗决策', orgnized_record, re.S).group(1).strip()\n",
    "        except AttributeError:\n",
    "            patient_progress = \"未提取到患者病情进展字段\"\n",
    "        \n",
    "        try:\n",
    "            doctor_decision = re.search(r'医生诊疗决策：(.*)', orgnized_record, re.S).group(1).strip()\n",
    "        except AttributeError:\n",
    "            doctor_decision = \"未提取到医生诊疗决策字段\"\n",
    "        \n",
    "        \n",
    "        input_task4 = f\"患者病情进展：{patient_progress}。\"\n",
    "        output_task4 = f\"医生诊疗决策：{doctor_decision}。\"\n",
    "    \n",
    "    # for record in records.iterrows():\n",
    "    #     if '日常查房记录' in record[1]['BL_TYPE']:\n",
    "    #         if '目前治疗' in record[1]['YZTL']:\n",
    "    #             drugs = re.search(r'目前治疗(.*?)\\n', record[1]['YZTL'], re.DOTALL).group(1).strip()\n",
    "    #             break\n",
    "    \n",
    "    # drugs = ''\n",
    "    # for index, record in records.iterrows():\n",
    "    #     if '日常查房记录' in record['BL_TYPE']:\n",
    "    #         if '目前治疗' in record['YZTL']:\n",
    "    #             drugs += re.search(r'目前治疗(.*?)\\n', record['YZTL'], re.DOTALL).group(1).strip()\n",
    "    #             drugs += ' '\n",
    "\n",
    "    # output = '医嘱用药：{}'.format(drugs)\n",
    "    # drugs_in_output = []\n",
    "    # for drug in drugs_kyy_kjsb:\n",
    "    #     if drug in output:\n",
    "    #         if drug == '西酞普兰' and '艾司西酞普兰' not in output:\n",
    "    #             drugs_in_output.append(drug)\n",
    "    #         elif drug == '西酞普兰' and '艾司西酞普兰' in output:\n",
    "    #             continue\n",
    "    #         else:\n",
    "    #             drugs_in_output.append(drug)\n",
    "    \n",
    "    # output_task4 = ', '.join(set(drugs_in_output))\n",
    "    # if len(output_task4.split(',')) > 5:\n",
    "    #     cases_missing_sth.append(ipid)\n",
    "        \n",
    "    # 创建数据集 task1\n",
    "    # conversation1 = []\n",
    "    # conversation1.append({'from':'IPID','value': str(ipid)})\n",
    "    # conversation1.append({'from':'human','value': input_info})\n",
    "    # conversation1.append({'from':'gpt','value': output_task1})\n",
    "    # conversations_1.append({'conversations': conversation1})\n",
    "    \n",
    "    # # 创建数据集 task2\n",
    "    # conversation2 = []\n",
    "    # conversation2.append({'from':'IPID','value': str(ipid)})\n",
    "    # conversation2.append({'from':'human','value': input_info})\n",
    "    # conversation2.append({'from':'gpt','value': output_task2})\n",
    "    # conversations_2.append({'conversations': conversation2})\n",
    "    \n",
    "    # # 创建数据集 task3\n",
    "    # conversation3 = []\n",
    "    # conversation3.append({'from':'IPID','value': str(ipid)})\n",
    "    # conversation3.append({'from':'human','value': input_info})\n",
    "    # conversation3.append({'from':'gpt','value': output_task3})\n",
    "    # conversations_3.append({'conversations': conversation3})\n",
    "    \n",
    "    # # 创建数据集 task4\n",
    "    conversation4 = []\n",
    "    conversation4.append({'from':'IPID','value': str(ipid)})\n",
    "    conversation4.append({'from':'human','value': input_info})\n",
    "    conversation4.append({'from':'gpt','value': output_task4})\n",
    "    conversations_4.append({'conversations': conversation4})\n",
    "\n",
    "# print(len(conversations_1))\n",
    "# print(len(conversations_2))\n",
    "# print(len(conversations_3))\n",
    "print(len(conversations_4))\n",
    "\n",
    "print(cases_missing_sth)\n",
    "\n",
    "# with open('./data/F2X-1223/task1-summary.jsonl', 'w') as file1:\n",
    "#     for item in conversations_1:\n",
    "#         # 将每个字典转换为JSON字符串并写入文件\n",
    "#         json_str = json.dumps(item, ensure_ascii=False)\n",
    "#         file1.write(json_str + '\\n')\n",
    "\n",
    "# with open('./data/F2X-1223/task2-diagnosis.jsonl', 'w') as file2:\n",
    "#     for item in conversations_2:\n",
    "#         # 将每个字典转换为JSON字符串并写入文件\n",
    "#         json_str = json.dumps(item, ensure_ascii=False)\n",
    "#         file2.write(json_str + '\\n')\n",
    "\n",
    "# with open('./data/F2X-1223/task3-treatment.jsonl', 'w') as file3:\n",
    "#     for item in conversations_3:\n",
    "#         # 将每个字典转换为JSON字符串并写入文件\n",
    "#         json_str = json.dumps(item, ensure_ascii=False)\n",
    "#         file3.write(json_str + '\\n')\n",
    "\n",
    "with open('./data/F2X-1223/task4-management.jsonl', 'w') as file4:\n",
    "    for item in conversations_4:\n",
    "        # 将每个字典转换为JSON字符串并写入文件\n",
    "        json_str = json.dumps(item, ensure_ascii=False)\n",
    "        file4.write(json_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "99\n",
      "99\n",
      "99\n",
      "[100201941898, 100201950521, 100201941875, 100201947059, 100201942654, 100201951733, 100201935802]\n"
     ]
    }
   ],
   "source": [
    "# 精分组\n",
    "\n",
    "conversations_1 = []\n",
    "conversations_2 = []\n",
    "conversations_3 = []\n",
    "conversations_4 = []\n",
    "\n",
    "cases_missing_sth = []\n",
    "\n",
    "for ipid in patient_info['住院唯一号'].unique():\n",
    "    patient = patient_info[patient_info['住院唯一号']==ipid]\n",
    "    records = case_record[case_record['住院唯一号']==ipid]\n",
    "    first_record = records[records['类别']=='首次病程']['病程内容'].iloc[0]\n",
    "    \n",
    "    # 准备输入字段\n",
    "    senior_record = pd.concat([records[records['类别']=='主任医师首次查房记录'], \n",
    "                               records[records['类别']=='副主任医师首次查房记录']], axis=0, ignore_index=True)\n",
    "    senior_record_content = senior_record['病程内容'].to_list()\n",
    "    if len(senior_record_content) == 0:\n",
    "        junior_record = records[records['类别']=='主治医师首次查房记录']\n",
    "        junior_record_content = junior_record['病程内容'].to_list()\n",
    "        if len(junior_record_content) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            senior_record_content = junior_record_content\n",
    "    senior_record_content.sort()\n",
    "    content = senior_record_content[0]\n",
    "    try:\n",
    "        mental_exam = re.search(r'精神检查：(.*?)对诊断及鉴别诊断分析', content, re.S).group(1).strip().split('精神检查')[1]\n",
    "    except:\n",
    "        mental_exam = re.search(r'精神检查：(.*?)对诊断及鉴别诊断分析', content, re.S).group(1).strip().split('精神检查')[0]\n",
    "    \n",
    "    base = '患者{}性，{}岁。\\n'.format(patient['性别'].iloc[0], patient['年龄'].iloc[0])\n",
    "    brief_his = '简要病史：' + re.search(r'4.临床表现：(.*?)5.既往史：', first_record, re.S).group(1).strip() + '\\n'    \n",
    "    past_his = '既往史：' + re.search(r'5.既往史：(.*?)6.家族史：', first_record, re.S).group(1).strip() + '\\n' \n",
    "    family_his = '家族史：' + re.search(r'6.家族史：(.*?)7.查体及辅助检查：', first_record, re.S).group(1).strip() + '\\n' \n",
    "    exam = '查体，精神检查及辅助检查：' + re.search(r'7.查体及辅助检查：(.*?)拟诊讨论：', first_record, re.S).group(1).strip() + mental_exam + '\\n' \n",
    "    if len(exam) < 20:\n",
    "        cases_missing_sth.append(ipid)\n",
    "    date_in = '入院日期：{}年{}月{}日'.format(str(patient['入院日期'].iloc[0])[:4], str(patient['入院日期'].iloc[0])[4:6], str(patient['入院日期'].iloc[0])[6:8])\n",
    "    \n",
    "    input_info = base + brief_his + past_his + family_his + exam + date_in\n",
    "    \n",
    "    # 准备输出字段-task1\n",
    "    zs = '主诉：{}\\n'.format(re.search(r'主因“(.*?)”入院', first_record, re.S).group(1).strip())\n",
    "    summary_1 = '1.病程标准：' + re.search(r'1.病程标准：(.*?)2.症状学标准', first_record, re.S).group(1).strip() + '\\n'\n",
    "    summary_2 = '2.症状学标准：' + re.search(r'2.症状学标准：(.*?)3.严重程度标准', first_record, re.S).group(1).strip() + '\\n'\n",
    "    summary_3 = '3.严重程度标准：' + re.search(r'3.严重程度标准：(.*?)4.排除标准', first_record, re.S).group(1).strip() + '\\n'\n",
    "    summary_4 = '4.排除标准：' + re.search(r'4.排除标准：(.*?)5.入院印象', first_record, re.S).group(1).strip() + '\\n'\n",
    "    summary = '病例特点：{}'.format(summary_1 + summary_2 + summary_3 + summary_4)\n",
    "    output_task1 = zs + summary\n",
    "    \n",
    "    # 准备输出字段-task2\n",
    "    diag_primary = '主要诊断：{}\\n'.format(patient['主要诊断名称'].iloc[0])\n",
    "    other_name = patient['其他诊断名称'].iloc[0]\n",
    "    other_code = patient['其他诊断ICD'].iloc[0]\n",
    "    other_mental_disease = \"\"\n",
    "    if 'F' in other_code:\n",
    "        other_list = other_code.split(',')\n",
    "        for idx, other_disease in enumerate(other_list):\n",
    "            if 'F' in other_disease:\n",
    "                other_mental_disease += other_name.split(',')[idx]\n",
    "                other_mental_disease += ';'\n",
    "        diag_other = '精神科共病诊断：{}\\n'.format(other_mental_disease)\n",
    "    else:\n",
    "        diag_other = '精神科共病诊断：无\\n'\n",
    "    \n",
    "    output_task2 = diag_primary + diag_other\n",
    "    \n",
    "    # 准备输出字段-task3\n",
    "    # senior_record = pd.concat([records[records['类别']=='主任医师首次查房记录'], \n",
    "    #                            records[records['类别']=='副主任医师首次查房记录']], axis=0, ignore_index=True)\n",
    "    # senior_record_content = senior_record['病程内容'].to_list()\n",
    "    # if len(senior_record_content) == 0:\n",
    "    #     junior_record = records[records['类别']=='主治医师首次查房记录']\n",
    "    #     junior_record_content = junior_record['病程内容'].to_list()\n",
    "    #     if len(junior_record_content) == 0:\n",
    "    #         continue\n",
    "    #     else:\n",
    "    #         senior_record_content = junior_record_content\n",
    "    # senior_record_content.sort()\n",
    "    # content = senior_record_content[0]\n",
    "    clean_analysis = re.search(r'对诊断及鉴别诊断分析：(.*?)诊疗原则及处理计划', content, re.S).group(1).strip()\n",
    "    differential = '鉴别诊断分析：{}'.format(clean_analysis)\n",
    "    \n",
    "    output_task3 = differential\n",
    "    \n",
    "    # 准备输出字段-task4\n",
    "    records = records.sort_values(by='病程内容')\n",
    "    drugs = ''\n",
    "    for index, record in records.iterrows():\n",
    "        if '日常查房记录' in record['类别']:\n",
    "            if '目前治疗' in record['病程内容']:\n",
    "                drugs += re.search(r'目前治疗(.*?)\\n', record['病程内容'], re.DOTALL).group(1).strip()\n",
    "                drugs += ' '\n",
    "\n",
    "    output = '医嘱用药：{}'.format(drugs)\n",
    "    drugs_in_output = []\n",
    "    for drug in drugs_kyy_kjsb:\n",
    "        if drug in output:\n",
    "            if drug == '西酞普兰' and '艾司西酞普兰' not in output:\n",
    "                drugs_in_output.append(drug)\n",
    "            elif drug == '西酞普兰' and '艾司西酞普兰' in output:\n",
    "                continue\n",
    "            else:\n",
    "                drugs_in_output.append(drug)\n",
    "    \n",
    "    output_task4 = ', '.join(set(drugs_in_output))\n",
    "    if len(output_task4.split(',')) > 5:\n",
    "        cases_missing_sth.append(ipid)\n",
    "        \n",
    "    # 创建数据集 task1\n",
    "    conversation1 = []\n",
    "    conversation1.append({'from':'IPID','value': str(ipid)})\n",
    "    conversation1.append({'from':'human','value': input_info})\n",
    "    conversation1.append({'from':'gpt','value': output_task1})\n",
    "    conversations_1.append({'conversations': conversation1})\n",
    "    \n",
    "    # 创建数据集 task2\n",
    "    conversation2 = []\n",
    "    conversation2.append({'from':'IPID','value': str(ipid)})\n",
    "    conversation2.append({'from':'human','value': input_info})\n",
    "    conversation2.append({'from':'gpt','value': output_task2})\n",
    "    conversations_2.append({'conversations': conversation2})\n",
    "    \n",
    "    # 创建数据集 task3\n",
    "    conversation3 = []\n",
    "    conversation3.append({'from':'IPID','value': str(ipid)})\n",
    "    conversation3.append({'from':'human','value': input_info})\n",
    "    conversation3.append({'from':'gpt','value': output_task3})\n",
    "    conversations_3.append({'conversations': conversation3})\n",
    "    \n",
    "    # 创建数据集 task4\n",
    "    conversation4 = []\n",
    "    conversation4.append({'from':'IPID','value': str(ipid)})\n",
    "    conversation4.append({'from':'human','value': input_info})\n",
    "    conversation4.append({'from':'gpt','value': output_task4})\n",
    "    conversations_4.append({'conversations': conversation4})\n",
    "\n",
    "print(len(conversations_1))\n",
    "print(len(conversations_2))\n",
    "print(len(conversations_3))\n",
    "print(len(conversations_4))\n",
    "\n",
    "print(cases_missing_sth)\n",
    "\n",
    "with open('./data/jingfen/task1-F20.jsonl', 'w') as file1:\n",
    "    for item in conversations_1:\n",
    "        # 将每个字典转换为JSON字符串并写入文件\n",
    "        json_str = json.dumps(item, ensure_ascii=False)\n",
    "        file1.write(json_str + '\\n')\n",
    "\n",
    "with open('./data/jingfen/task2-F20.jsonl', 'w') as file2:\n",
    "    for item in conversations_2:\n",
    "        # 将每个字典转换为JSON字符串并写入文件\n",
    "        json_str = json.dumps(item, ensure_ascii=False)\n",
    "        file2.write(json_str + '\\n')\n",
    "\n",
    "with open('./data/jingfen/task3-F20.jsonl', 'w') as file3:\n",
    "    for item in conversations_3:\n",
    "        # 将每个字典转换为JSON字符串并写入文件\n",
    "        json_str = json.dumps(item, ensure_ascii=False)\n",
    "        file3.write(json_str + '\\n')\n",
    "\n",
    "with open('./data/jingfen/task4-F20.jsonl', 'w') as file4:\n",
    "    for item in conversations_4:\n",
    "        # 将每个字典转换为JSON字符串并写入文件\n",
    "        json_str = json.dumps(item, ensure_ascii=False)\n",
    "        file4.write(json_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "# 添加指令instruction\n",
    "import random\n",
    "import json\n",
    "\n",
    "instructions_1 = [\n",
    "    \"请根据提供的患者信息提炼主诉，并依据ICD-10标准总结该患者的诊断标准，包括病程、症状学、严重程度和排除标准。\",\n",
    "    \"根据患者的资料，提取其主诉，并按照ICD-10标准总结诊断标准，涵盖病程、症状、严重程度和排除标准。\",\n",
    "    \"依据提供的患者信息，提取其主诉，并依照ICD-10标准总结诊断标准，包括病程标准、症状标准、严重程度标准和排除标准。\",\n",
    "    \"请从患者信息中提取主诉，并依据ICD-10的相应标准，总结该患者的诊断标准，包括病程、症状、严重程度及排除标准。\",\n",
    "    \"根据提供的患者资料，提取其主诉，并根据ICD-10标准总结其诊断标准，包括病程标准、症状学标准、严重程度标准及排除标准。\",\n",
    "    \"请根据患者信息提取主诉，并按照ICD-10标准总结该患者的诊断标准，包括病程、症状、严重程度和排除标准。\",\n",
    "    \"从患者信息中提取主诉，并根据ICD-10标准总结其诊断标准，包括病程、症状、严重程度和排除标准。\",\n",
    "    \"根据提供的患者信息，提取主诉，并按照ICD-10标准总结诊断标准，涵盖病程、症状、严重程度及排除标准。\",\n",
    "    \"请依据提供的患者信息，提炼主诉，并依照ICD-10标准总结其诊断标准，包括病程、症状、严重程度和排除标准。\",\n",
    "    \"根据患者资料，提取其主诉，并根据ICD-10标准总结诊断标准，包括病程、症状、严重程度及排除标准。\",\n",
    "    \"请从患者信息中提炼出主诉，并依据ICD-10标准总结诊断标准，包括病程、症状、严重程度及排除标准。\",\n",
    "    \"根据提供的患者资料，提取主诉，并依据ICD-10的相应标准，总结诊断标准，包括病程标准、症状学标准、严重程度标准和排除标准。\",\n",
    "    \"请根据患者信息提炼其主诉，并依照ICD-10标准总结诊断标准，包括病程、症状、严重程度和排除标准。\",\n",
    "    \"从患者信息中提取主诉，并依据ICD-10标准总结其诊断标准，包括病程、症状、严重程度及排除标准。\",\n",
    "    \"根据提供的患者资料，提取其主诉，并按照ICD-10标准总结诊断标准，涵盖病程、症状、严重程度及排除标准。\",\n",
    "    \"请依据提供的患者信息，提取主诉，并根据ICD-10标准总结诊断标准，包括病程标准、症状学标准、严重程度标准和排除标准。\",\n",
    "    \"根据患者资料，提取其主诉，并依照ICD-10标准总结诊断标准，包括病程、症状、严重程度及排除标准。\",\n",
    "    \"请从患者信息中提炼主诉，并按照ICD-10标准总结诊断标准，包括病程、症状、严重程度和排除标准。\",\n",
    "    \"根据提供的患者信息，提取其主诉，并依照ICD-10标准总结诊断标准，涵盖病程、症状、严重程度及排除标准。\",\n",
    "    \"请根据患者资料提取主诉，并依据ICD-10标准总结其诊断标准，包括病程标准、症状学标准、严重程度标准及排除标准。\",\n",
    "]\n",
    "\n",
    "instructions_2 = [\n",
    "    \"根据下述患者信息按照ICD-10诊断标准给出主要诊断以及共病诊断（若有）的疾病名称（精确到亚型）。仅需要给出诊断疾病名称，无需进行分析。\",\n",
    "    \"根据以下患者信息，依据ICD-10标准提供主要诊断和共病诊断（若有）的疾病名称（精确到亚型）。只需给出诊断的疾病名称，无需分析。\",\n",
    "    \"请根据患者信息，按照ICD-10标准给出主要诊断和共病诊断（若有）的疾病名称（具体到亚型）。仅需提供疾病名称，不需要进行分析。\",\n",
    "    \"依据下述患者信息，根据ICD-10标准提供主要诊断及共病诊断（若有）的疾病名称（详细到亚型）。只需提供诊断的疾病名称，无需分析。\",\n",
    "    \"根据以下患者资料，按照ICD-10标准给出主要诊断和共病诊断（若有）的具体疾病名称。只需提供疾病名称，无需分析。\",\n",
    "    \"请依据下述患者信息，按照ICD-10标准给出主要诊断和共病诊断（如有）的具体疾病名称。只需提供诊断的名称，无需分析。\",\n",
    "    \"根据患者资料，依照ICD-10标准给出主要诊断及共病诊断（如有）的疾病名称（详细到亚型）。仅需提供疾病名称，无需进行分析。\",\n",
    "    \"请根据以下患者信息，按照ICD-10标准给出主要诊断和共病诊断（如有）的具体疾病名称。只需提供诊断的名称，无需分析。\",\n",
    "    \"依据下述患者资料，按照ICD-10标准给出主要诊断及共病诊断（如有）的疾病名称（具体到亚型）。仅需提供疾病名称，不需分析。\",\n",
    "    \"根据患者信息，依据ICD-10标准提供主要诊断和共病诊断（若有）的详细疾病名称。只需提供疾病名称，无需进行分析。\",\n",
    "    \"请依据以下患者信息，按照ICD-10标准给出主要诊断和共病诊断（若有）的具体疾病名称。仅需提供名称，无需分析。\",\n",
    "    \"根据以下患者资料，依据ICD-10标准提供主要诊断及共病诊断（如有）的疾病名称（精确到亚型）。只需给出诊断的名称，无需进行分析。\",\n",
    "    \"请根据下述患者信息，依照ICD-10标准给出主要诊断及共病诊断（若有）的疾病名称（详细到亚型）。仅需提供疾病名称，无需分析。\",\n",
    "    \"根据患者资料，按照ICD-10标准给出主要诊断和共病诊断（若有）的疾病名称（具体到亚型）。只需提供名称，无需分析。\",\n",
    "    \"依据以下患者信息，依照ICD-10标准提供主要诊断和共病诊断（如有）的详细疾病名称。只需提供诊断的名称，不需要分析。\",\n",
    "    \"请根据下述患者资料，依据ICD-10标准给出主要诊断及共病诊断（如有）的具体疾病名称。仅需提供名称，无需分析。\",\n",
    "    \"根据患者信息，依照ICD-10标准提供主要诊断和共病诊断（若有）的疾病名称（具体到亚型）。只需给出名称，无需分析。\",\n",
    "    \"请依据以下患者信息，按照ICD-10标准提供主要诊断及共病诊断（如有）的具体疾病名称。仅需提供诊断的名称，无需分析。\",\n",
    "    \"根据下述患者资料，依据ICD-10标准给出主要诊断和共病诊断（若有）的详细疾病名称。只需提供名称，无需分析。\",\n",
    "    \"请依据患者信息，依照ICD-10标准提供主要诊断及共病诊断（如有）的疾病名称（具体到亚型）。仅需提供名称，无需分析。\",\n",
    "]\n",
    "\n",
    "instructions_3 = [\n",
    "    \"根据以下患者信息，进行精神心理疾病之间的临床鉴别诊断分析，给出主要诊断和可能的鉴别诊断。\",\n",
    "    \"根据以下患者信息，进行精神心理疾病的临床鉴别诊断，确定主要诊断并列出可能的鉴别诊断。\",\n",
    "    \"根据提供的患者资料，进行精神心理疾病的鉴别诊断分析，确定主要诊断和可能的鉴别诊断。\",\n",
    "    \"请根据以下患者信息，进行精神心理疾病的临床分析，提供主要诊断及可能的鉴别诊断。\",\n",
    "    \"依据以下患者资料，进行精神心理疾病的鉴别诊断分析，给出主要诊断及潜在的鉴别诊断。\",\n",
    "    \"根据以下患者信息，分析精神心理疾病的临床表现，提供主要诊断及可能的鉴别诊断。\",\n",
    "    \"请依据以下患者资料，进行精神心理疾病的鉴别诊断，确定主要诊断并列出可能的鉴别诊断。\",\n",
    "    \"根据提供的患者信息，进行精神心理疾病的临床分析，给出主要诊断及潜在的鉴别诊断。\",\n",
    "    \"请根据以下患者资料，分析精神心理疾病的临床表现，提供主要诊断及可能的鉴别诊断。\",\n",
    "    \"依据以下患者信息，进行精神心理疾病的鉴别诊断分析，确定主要诊断和潜在的鉴别诊断。\",\n",
    "    \"根据以下患者资料，进行精神心理疾病的临床鉴别，提供主要诊断和可能的鉴别诊断。\",\n",
    "    \"请依据提供的患者信息，进行精神心理疾病的鉴别诊断，给出主要诊断及潜在的鉴别诊断。\",\n",
    "    \"根据以下患者资料，分析精神心理疾病的临床表现，确定主要诊断和可能的鉴别诊断。\",\n",
    "    \"请根据患者信息，进行精神心理疾病的临床鉴别诊断，提供主要诊断及可能的鉴别诊断。\",\n",
    "    \"依据患者资料，进行精神心理疾病的临床分析，给出主要诊断及潜在的鉴别诊断。\",\n",
    "    \"根据患者信息，进行精神心理疾病的鉴别诊断，确定主要诊断和可能的鉴别诊断。\",\n",
    "    \"请根据患者资料，进行精神心理疾病的临床鉴别诊断分析，提供主要诊断及可能的鉴别诊断。\",\n",
    "    \"依据患者信息，分析精神心理疾病的临床表现，给出主要诊断及潜在的鉴别诊断。\",\n",
    "    \"根据患者资料，进行精神心理疾病的鉴别诊断分析，确定主要诊断及可能的鉴别诊断。\",\n",
    "    \"请根据提供的患者资料，分析精神心理疾病，提供主要诊断和可能的鉴别诊断。\",\n",
    "]\n",
    "\n",
    "instructions_4 = [\n",
    "    \"根据患者当前的病情信息，给出最合适的精神科药物治疗用药建议。\",\n",
    "    \"请依据患者的现有病情信息，提供最佳的精神科药物治疗建议。\",\n",
    "    \"根据患者目前的病情，推荐最合适的精神科药物治疗方案。\",\n",
    "    \"请根据患者的当前病情，给出最适合的精神科药物治疗建议。\",\n",
    "    \"依据患者的病情信息，提供最合适的精神科药物治疗建议。\",\n",
    "    \"根据患者的现有病情，提出最佳的精神科药物治疗方案。\",\n",
    "    \"请依据患者当前的病情信息，推荐最适合的精神科药物治疗。\",\n",
    "    \"根据患者的目前病情，给出最合适的精神科药物治疗方案。\",\n",
    "    \"请根据患者的现有病情信息，提供最佳的精神科药物治疗建议。\",\n",
    "    \"依据患者当前的病情，提出最适合的精神科药物治疗建议。\",\n",
    "    \"根据患者的病情信息，推荐最合适的精神科药物治疗方案。\",\n",
    "    \"请依据患者现有的病情信息，给出最合适的精神科药物治疗建议。\",\n",
    "    \"根据患者当前的病情，提供最佳的精神科药物治疗建议。\",\n",
    "    \"请根据患者的目前病情信息，提出最适合的精神科药物治疗方案。\",\n",
    "    \"依据患者的现有病情，给出最合适的精神科药物治疗建议。\",\n",
    "    \"根据患者当前的病情信息，推荐最佳的精神科药物治疗方案。\",\n",
    "    \"请依据患者的病情信息，提供最合适的精神科药物治疗方案。\",\n",
    "    \"根据患者的现有病情，给出最佳的精神科药物治疗建议。\",\n",
    "    \"请根据患者的目前病情信息，推荐最适合的精神科药物治疗。\",\n",
    "    \"依据患者当前的病情信息，提出最佳的精神科药物治疗建议。\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# path1 = r'D:\\work\\code\\psychgpt\\sft\\data\\backup1\\task1.jsonl'\n",
    "# path2 = r'D:\\work\\code\\psychgpt\\sft\\data\\backup1\\task2.jsonl'\n",
    "# path3 = r'D:\\work\\code\\psychgpt\\sft\\data\\backup1\\task3.jsonl'\n",
    "# path4 = r'D:\\work\\code\\psychgpt\\sft\\data\\backup1\\task4.jsonl'\n",
    "\n",
    "path1 = r'D:\\work\\code\\psychgpt\\sft\\data\\jingfen\\task1-F20.jsonl'\n",
    "path2 = r'D:\\work\\code\\psychgpt\\sft\\data\\jingfen\\task2-F20.jsonl'\n",
    "path3 = r'D:\\work\\code\\psychgpt\\sft\\data\\jingfen\\task3-F20.jsonl'\n",
    "path4 = r'D:\\work\\code\\psychgpt\\sft\\data\\jingfen\\task4-F20.jsonl'\n",
    "\n",
    "path0 = r'D:\\work\\code\\psychgpt_benchmark\\benchmark_0720\\task1.jsonl'\n",
    "ipid_filtout = []\n",
    "with open(path0, 'r') as file0:\n",
    "    for line in file0:\n",
    "        newline = eval(line)\n",
    "        ipid_filtout.append(newline['conversations'][0]['value'])\n",
    "file0.close()\n",
    "\n",
    "\n",
    "\n",
    "data1 = []\n",
    "with open(path1, 'r') as file1:\n",
    "    for line in file1:\n",
    "        newline = eval(line)\n",
    "        data1.append(newline)\n",
    "file1.close()\n",
    "\n",
    "data2 = []\n",
    "with open(path2, 'r') as file2:\n",
    "    for line in file2:\n",
    "        newline = eval(line)\n",
    "        data2.append(newline)\n",
    "file2.close()\n",
    "     \n",
    "data3 = []\n",
    "with open(path3, 'r') as file3:\n",
    "    for line in file3:\n",
    "        newline = eval(line)\n",
    "        data3.append(newline)\n",
    "file3.close()\n",
    "        \n",
    "data4 = []\n",
    "with open(path4, 'r') as file4:\n",
    "    for line in file4:\n",
    "        newline = eval(line)\n",
    "        data4.append(newline)\n",
    "file4.close()\n",
    "\n",
    "exist_in_data1 = False\n",
    "exist_in_data2 = False\n",
    "exist_in_data3 = False\n",
    "exist_in_data4 = False\n",
    "\n",
    "selected_data1 = []\n",
    "selected_data2 = []\n",
    "selected_data3 = []\n",
    "selected_data4 = []\n",
    "\n",
    "cnt = 0\n",
    "for item in data1:\n",
    "    ipid = item['conversations'][0]['value']\n",
    "    if ipid in ipid_filtout:\n",
    "        continue\n",
    "    \n",
    "    for item2 in data2:\n",
    "        if item2['conversations'][0]['value'] == ipid:\n",
    "            exist_in_data2 = True\n",
    "            break\n",
    "    \n",
    "    for item3 in data3:\n",
    "        if item3['conversations'][0]['value'] == ipid:\n",
    "            exist_in_data3 = True\n",
    "            break\n",
    "    \n",
    "    for item4 in data4:\n",
    "        if item4['conversations'][0]['value'] == ipid:\n",
    "            exist_in_data4 = True\n",
    "            break\n",
    "    \n",
    "    \n",
    "    if exist_in_data2 == True and exist_in_data3 == True and exist_in_data4 == True:\n",
    "        print(cnt)\n",
    "        # current_his = re.search(r'简要病史：(.*?)(?=查体及精神检查)', item['conversations'][1]['value'], re.DOTALL).group(1).strip()\n",
    "        input_info = item['conversations'][1]['value']\n",
    "    \n",
    "\n",
    "        input1 = \"{}\\n 患者信息：{}\\n\".format(random.choice(instructions_1), input_info)\n",
    "        label1 = item['conversations'][2]['value']\n",
    "        conversation1 = []\n",
    "        conversation1.append({'from':'human','value': input1})\n",
    "        conversation1.append({'from':'gpt','value': label1})\n",
    "        selected_data1.append({'conversations': conversation1})\n",
    "        \n",
    "        input2 = \"{}\\n 患者信息：{}\\n\".format(random.choice(instructions_2), input_info)\n",
    "        label2 = item2['conversations'][2]['value']\n",
    "        conversation2 = []\n",
    "        conversation2.append({'from':'human','value': input2})\n",
    "        conversation2.append({'from':'gpt','value': label2})\n",
    "        selected_data2.append({'conversations': conversation2})\n",
    "        \n",
    "        input3 = \"{}\\n 患者信息：{}\\n\".format(random.choice(instructions_3), input_info)\n",
    "        label3 = item3['conversations'][2]['value']\n",
    "        conversation3 = []\n",
    "        conversation3.append({'from':'human','value': input3})\n",
    "        conversation3.append({'from':'gpt','value': label3})\n",
    "        selected_data3.append({'conversations': conversation3})\n",
    "\n",
    "        input4 = \"{}\\n 患者信息：{}\\n\".format(random.choice(instructions_4), input_info)\n",
    "        label4 = item4['conversations'][2]['value']\n",
    "        conversation4 = []\n",
    "        conversation4.append({'from':'human','value': input4})\n",
    "        conversation4.append({'from':'gpt','value': label4})\n",
    "        selected_data4.append({'conversations': conversation4})\n",
    "        \n",
    "        \n",
    "        cnt += 1\n",
    "        exist_in_data1 = False\n",
    "        exist_in_data2 = False\n",
    "        exist_in_data4 = False\n",
    "\n",
    "with open(r'D:\\work\\code\\psychgpt\\sft\\data\\task1_new_F20.jsonl', 'w') as file1:\n",
    "    for item in selected_data1:\n",
    "        # 将每个字典转换为JSON字符串并写入文件\n",
    "        json_str = json.dumps(item, ensure_ascii=False)\n",
    "        file1.write(json_str + '\\n')\n",
    "file1.close()\n",
    "\n",
    "with open(r'D:\\work\\code\\psychgpt\\sft\\data\\task2_new_F20.jsonl', 'w') as file2:\n",
    "    for item in selected_data2:\n",
    "        # 将每个字典转换为JSON字符串并写入文件\n",
    "        json_str = json.dumps(item, ensure_ascii=False)\n",
    "        file2.write(json_str + '\\n')\n",
    "file2.close()\n",
    "\n",
    "with open(r'D:\\work\\code\\psychgpt\\sft\\data\\task3_new_F20.jsonl', 'w') as file3:\n",
    "    for item in selected_data3:\n",
    "        # 将每个字典转换为JSON字符串并写入文件\n",
    "        json_str = json.dumps(item, ensure_ascii=False)\n",
    "        file3.write(json_str + '\\n')\n",
    "file3.close()\n",
    "\n",
    "with open(r'D:\\work\\code\\psychgpt\\sft\\data\\task4_new_F20.jsonl', 'w') as file4:\n",
    "    for item in selected_data4:\n",
    "        # 将每个字典转换为JSON字符串并写入文件\n",
    "        json_str = json.dumps(item, ensure_ascii=False)\n",
    "        file4.write(json_str + '\\n')\n",
    "file4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass 1\n",
      "pass 2\n",
      "pass 3\n",
      "pass 4\n",
      "pass 5\n",
      "pass 6\n",
      "pass 7\n",
      "pass 8\n",
      "pass 9\n",
      "pass 10\n",
      "pass 11\n",
      "pass 12\n",
      "pass 13\n",
      "pass 14\n",
      "pass 15\n",
      "pass 16\n",
      "pass 17\n",
      "pass 18\n",
      "pass 19\n",
      "pass 20\n",
      "pass 21\n",
      "pass 22\n",
      "pass 23\n",
      "pass 24\n",
      "pass 25\n",
      "pass 26\n",
      "pass 27\n",
      "pass 28\n",
      "pass 29\n",
      "pass 30\n",
      "pass 31\n",
      "pass 32\n",
      "pass 33\n",
      "pass 34\n",
      "pass 35\n",
      "pass 36\n",
      "pass 37\n",
      "pass 38\n",
      "pass 39\n",
      "pass 40\n",
      "pass 41\n",
      "pass 42\n",
      "pass 43\n",
      "pass 44\n",
      "pass 45\n",
      "pass 46\n",
      "pass 47\n",
      "pass 48\n",
      "pass 49\n",
      "pass 50\n",
      "pass 51\n",
      "pass 52\n",
      "pass 53\n",
      "pass 54\n",
      "pass 55\n",
      "pass 56\n",
      "pass 57\n",
      "pass 58\n",
      "pass 59\n",
      "pass 60\n",
      "pass 61\n",
      "pass 62\n",
      "pass 63\n",
      "pass 64\n",
      "pass 65\n",
      "pass 66\n",
      "pass 67\n",
      "pass 68\n",
      "pass 69\n",
      "pass 70\n",
      "pass 71\n",
      "pass 72\n",
      "pass 73\n",
      "pass 74\n",
      "pass 75\n",
      "pass 76\n",
      "pass 77\n",
      "pass 78\n",
      "pass 79\n",
      "pass 80\n",
      "pass 81\n",
      "pass 82\n",
      "pass 83\n",
      "pass 84\n",
      "pass 85\n",
      "pass 86\n",
      "pass 87\n",
      "pass 88\n",
      "pass 89\n",
      "pass 90\n",
      "pass 91\n",
      "pass 92\n",
      "pass 93\n",
      "pass 94\n",
      "pass 95\n",
      "pass 96\n",
      "pass 97\n",
      "pass 98\n",
      "pass 99\n",
      "pass 100\n",
      "pass 101\n",
      "pass 102\n",
      "pass 103\n",
      "pass 104\n",
      "pass 105\n",
      "pass 106\n",
      "pass 107\n",
      "pass 108\n",
      "pass 109\n",
      "pass 110\n",
      "pass 111\n",
      "pass 112\n",
      "pass 113\n",
      "pass 114\n",
      "pass 115\n",
      "pass 116\n",
      "pass 117\n",
      "pass 118\n",
      "pass 119\n",
      "pass 120\n",
      "pass 121\n",
      "pass 122\n",
      "pass 123\n",
      "pass 124\n",
      "pass 125\n",
      "pass 126\n",
      "pass 127\n",
      "pass 128\n",
      "pass 129\n",
      "pass 130\n",
      "pass 131\n",
      "pass 132\n",
      "pass 133\n",
      "pass 134\n",
      "pass 135\n",
      "pass 136\n",
      "pass 137\n",
      "pass 138\n",
      "pass 139\n",
      "pass 140\n",
      "pass 141\n",
      "pass 142\n",
      "pass 143\n",
      "pass 144\n",
      "pass 145\n",
      "pass 146\n",
      "pass 147\n",
      "pass 148\n",
      "pass 149\n",
      "pass 150\n",
      "pass 151\n",
      "pass 152\n",
      "pass 153\n",
      "pass 154\n",
      "pass 155\n",
      "pass 156\n",
      "pass 157\n",
      "pass 158\n",
      "pass 159\n",
      "pass 160\n",
      "pass 161\n",
      "pass 162\n",
      "pass 163\n",
      "pass 164\n",
      "pass 165\n",
      "pass 166\n",
      "pass 167\n",
      "pass 168\n",
      "pass 169\n",
      "pass 170\n",
      "pass 171\n",
      "pass 172\n",
      "pass 173\n",
      "pass 174\n",
      "pass 175\n",
      "pass 176\n",
      "pass 177\n",
      "pass 178\n",
      "pass 179\n",
      "pass 180\n",
      "pass 181\n",
      "pass 182\n",
      "pass 183\n",
      "pass 184\n",
      "pass 185\n",
      "pass 186\n",
      "pass 187\n",
      "pass 188\n",
      "pass 189\n",
      "pass 190\n",
      "pass 191\n",
      "pass 192\n",
      "pass 193\n",
      "pass 194\n",
      "pass 195\n",
      "pass 196\n",
      "pass 197\n",
      "pass 198\n",
      "pass 199\n",
      "pass 200\n",
      "pass 201\n",
      "pass 202\n",
      "pass 203\n",
      "pass 204\n",
      "pass 205\n",
      "pass 206\n",
      "pass 207\n",
      "pass 208\n",
      "pass 209\n",
      "pass 210\n",
      "pass 211\n",
      "pass 212\n",
      "pass 213\n",
      "pass 214\n",
      "pass 215\n",
      "pass 216\n",
      "pass 217\n",
      "pass 218\n",
      "pass 219\n",
      "pass 220\n",
      "pass 221\n",
      "pass 222\n",
      "pass 223\n",
      "pass 224\n",
      "pass 225\n",
      "pass 226\n",
      "pass 227\n",
      "pass 228\n",
      "pass 229\n",
      "pass 230\n",
      "pass 231\n",
      "pass 232\n",
      "pass 233\n",
      "pass 234\n",
      "pass 235\n",
      "pass 236\n",
      "pass 237\n",
      "pass 238\n",
      "pass 239\n",
      "pass 240\n",
      "pass 241\n",
      "pass 242\n",
      "pass 243\n",
      "pass 244\n",
      "pass 245\n",
      "pass 246\n",
      "pass 247\n",
      "pass 248\n",
      "pass 249\n",
      "pass 250\n",
      "pass 251\n",
      "pass 252\n",
      "pass 253\n",
      "pass 254\n",
      "pass 255\n",
      "pass 256\n",
      "pass 257\n",
      "pass 258\n",
      "pass 259\n",
      "pass 260\n",
      "pass 261\n",
      "pass 262\n",
      "pass 263\n",
      "pass 264\n",
      "pass 265\n",
      "pass 266\n",
      "pass 267\n",
      "pass 268\n",
      "pass 269\n",
      "pass 270\n",
      "pass 271\n",
      "pass 272\n",
      "pass 273\n",
      "pass 274\n",
      "pass 275\n",
      "pass 276\n",
      "pass 277\n",
      "pass 278\n",
      "pass 279\n",
      "pass 280\n",
      "pass 281\n",
      "pass 282\n",
      "pass 283\n",
      "pass 284\n",
      "pass 285\n",
      "pass 286\n",
      "pass 287\n",
      "pass 288\n",
      "pass 289\n",
      "pass 290\n",
      "pass 291\n",
      "pass 292\n",
      "pass 293\n",
      "pass 294\n",
      "pass 295\n",
      "pass 296\n",
      "pass 297\n",
      "pass 298\n",
      "pass 299\n",
      "pass 300\n",
      "pass 301\n",
      "pass 302\n",
      "pass 303\n",
      "pass 304\n",
      "pass 305\n",
      "pass 306\n",
      "pass 307\n",
      "pass 308\n",
      "pass 309\n",
      "pass 310\n",
      "pass 311\n",
      "pass 312\n",
      "pass 313\n",
      "pass 314\n",
      "pass 315\n",
      "pass 316\n",
      "pass 317\n",
      "pass 318\n",
      "pass 319\n",
      "pass 320\n",
      "pass 321\n",
      "pass 322\n",
      "pass 323\n",
      "pass 324\n",
      "pass 325\n",
      "pass 326\n",
      "pass 327\n",
      "pass 328\n",
      "pass 329\n",
      "pass 330\n",
      "pass 331\n",
      "pass 332\n",
      "pass 333\n",
      "pass 334\n",
      "pass 335\n",
      "pass 336\n",
      "pass 337\n",
      "pass 338\n",
      "pass 339\n",
      "pass 340\n",
      "pass 341\n",
      "pass 342\n",
      "pass 343\n",
      "pass 344\n",
      "pass 345\n",
      "pass 346\n",
      "pass 347\n",
      "pass 348\n",
      "pass 349\n",
      "pass 350\n",
      "pass 351\n",
      "pass 352\n",
      "pass 353\n",
      "pass 354\n",
      "pass 355\n",
      "pass 356\n",
      "pass 357\n",
      "pass 358\n",
      "pass 359\n",
      "pass 360\n",
      "pass 361\n",
      "pass 362\n",
      "pass 363\n",
      "pass 364\n",
      "pass 365\n",
      "pass 366\n",
      "pass 367\n",
      "pass 368\n",
      "pass 369\n",
      "pass 370\n",
      "pass 371\n",
      "pass 372\n",
      "pass 373\n",
      "pass 374\n",
      "pass 375\n",
      "pass 376\n",
      "pass 377\n",
      "pass 378\n",
      "pass 379\n",
      "pass 380\n",
      "pass 381\n",
      "pass 382\n",
      "pass 383\n",
      "pass 384\n",
      "pass 385\n",
      "pass 386\n",
      "pass 387\n",
      "pass 388\n",
      "pass 389\n",
      "pass 390\n",
      "pass 391\n",
      "pass 392\n",
      "pass 393\n",
      "pass 394\n",
      "pass 395\n",
      "pass 396\n",
      "pass 397\n",
      "pass 398\n",
      "pass 399\n",
      "pass 400\n",
      "pass 401\n",
      "pass 402\n",
      "pass 403\n",
      "pass 404\n",
      "pass 405\n",
      "pass 406\n",
      "pass 407\n",
      "pass 408\n",
      "pass 409\n",
      "pass 410\n",
      "pass 411\n",
      "pass 412\n",
      "pass 413\n",
      "pass 414\n",
      "pass 415\n",
      "pass 416\n",
      "pass 417\n",
      "pass 418\n",
      "pass 419\n",
      "pass 420\n",
      "pass 421\n",
      "pass 422\n",
      "pass 423\n",
      "pass 424\n",
      "pass 425\n",
      "pass 426\n",
      "pass 427\n",
      "pass 428\n",
      "pass 429\n",
      "pass 430\n",
      "pass 431\n",
      "pass 432\n",
      "pass 433\n",
      "pass 434\n",
      "pass 435\n",
      "pass 436\n",
      "pass 437\n",
      "pass 438\n",
      "pass 439\n",
      "pass 440\n",
      "pass 441\n",
      "pass 442\n",
      "pass 443\n",
      "pass 444\n",
      "pass 445\n",
      "pass 446\n",
      "pass 447\n",
      "pass 448\n",
      "pass 449\n",
      "pass 450\n",
      "pass 451\n",
      "pass 452\n",
      "pass 453\n",
      "pass 454\n",
      "pass 455\n",
      "pass 456\n",
      "pass 457\n",
      "pass 458\n",
      "pass 459\n",
      "pass 460\n",
      "pass 461\n",
      "pass 462\n",
      "pass 463\n",
      "pass 464\n",
      "pass 465\n",
      "pass 466\n",
      "pass 467\n",
      "pass 468\n",
      "pass 469\n",
      "pass 470\n",
      "pass 471\n",
      "pass 472\n",
      "pass 473\n",
      "pass 474\n",
      "pass 475\n",
      "pass 476\n",
      "pass 477\n",
      "pass 478\n",
      "pass 479\n",
      "pass 480\n",
      "pass 481\n",
      "pass 482\n",
      "pass 483\n",
      "pass 484\n",
      "pass 485\n",
      "pass 486\n",
      "pass 487\n",
      "pass 488\n",
      "pass 489\n",
      "pass 490\n",
      "pass 491\n",
      "pass 492\n",
      "pass 493\n",
      "pass 494\n",
      "pass 495\n",
      "pass 496\n",
      "pass 497\n",
      "pass 498\n",
      "pass 499\n",
      "pass 500\n",
      "pass 501\n",
      "pass 502\n",
      "pass 503\n",
      "pass 504\n",
      "pass 505\n",
      "pass 506\n",
      "pass 507\n",
      "pass 508\n",
      "pass 509\n",
      "pass 510\n",
      "pass 511\n",
      "pass 512\n",
      "pass 513\n",
      "pass 514\n",
      "pass 515\n",
      "pass 516\n",
      "pass 517\n",
      "pass 518\n",
      "pass 519\n",
      "pass 520\n",
      "pass 521\n",
      "pass 522\n",
      "pass 523\n",
      "pass 524\n",
      "pass 525\n",
      "pass 526\n",
      "pass 527\n",
      "pass 528\n",
      "pass 529\n",
      "pass 530\n",
      "pass 531\n",
      "pass 532\n",
      "pass 533\n",
      "pass 534\n",
      "pass 535\n",
      "pass 536\n",
      "pass 537\n",
      "pass 538\n",
      "pass 539\n",
      "pass 540\n",
      "pass 541\n",
      "pass 542\n",
      "pass 543\n",
      "pass 544\n",
      "pass 545\n",
      "pass 546\n",
      "pass 547\n",
      "pass 548\n",
      "pass 549\n",
      "pass 550\n",
      "pass 551\n",
      "pass 552\n",
      "pass 553\n",
      "pass 554\n",
      "pass 555\n",
      "pass 556\n",
      "pass 557\n",
      "pass 558\n",
      "pass 559\n",
      "pass 560\n",
      "pass 561\n",
      "pass 562\n",
      "pass 563\n",
      "pass 564\n",
      "pass 565\n",
      "pass 566\n",
      "pass 567\n",
      "pass 568\n",
      "pass 569\n",
      "pass 570\n",
      "pass 571\n",
      "pass 572\n",
      "pass 573\n",
      "pass 574\n",
      "pass 575\n",
      "pass 576\n",
      "pass 577\n",
      "pass 578\n",
      "pass 579\n",
      "pass 580\n",
      "pass 581\n",
      "pass 582\n",
      "pass 583\n",
      "pass 584\n",
      "pass 585\n",
      "pass 586\n",
      "pass 587\n",
      "pass 588\n",
      "pass 589\n",
      "pass 590\n",
      "pass 591\n",
      "pass 592\n",
      "pass 593\n",
      "pass 594\n",
      "pass 595\n",
      "pass 596\n",
      "pass 597\n",
      "pass 598\n",
      "pass 599\n",
      "pass 600\n",
      "pass 601\n",
      "pass 602\n",
      "pass 603\n",
      "pass 604\n",
      "pass 605\n",
      "pass 606\n",
      "pass 607\n",
      "pass 608\n",
      "pass 609\n",
      "pass 610\n",
      "pass 611\n",
      "pass 612\n",
      "pass 613\n",
      "pass 614\n",
      "pass 615\n",
      "pass 616\n",
      "pass 617\n",
      "pass 618\n",
      "pass 619\n",
      "pass 620\n",
      "pass 621\n",
      "pass 622\n",
      "pass 623\n",
      "pass 624\n",
      "pass 625\n",
      "pass 626\n",
      "pass 627\n",
      "pass 628\n",
      "pass 629\n",
      "pass 630\n",
      "pass 631\n",
      "pass 632\n",
      "pass 633\n",
      "pass 634\n",
      "pass 635\n",
      "pass 636\n",
      "pass 637\n",
      "pass 638\n",
      "pass 639\n",
      "pass 640\n",
      "pass 641\n",
      "pass 642\n",
      "pass 643\n",
      "pass 644\n",
      "pass 645\n",
      "pass 646\n",
      "pass 647\n",
      "pass 648\n",
      "pass 649\n",
      "pass 650\n",
      "pass 651\n",
      "pass 652\n",
      "pass 653\n",
      "pass 654\n",
      "pass 655\n",
      "pass 656\n",
      "pass 657\n",
      "pass 658\n",
      "pass 659\n",
      "pass 660\n",
      "pass 661\n",
      "pass 662\n",
      "pass 663\n",
      "pass 664\n",
      "pass 665\n",
      "pass 666\n",
      "pass 667\n",
      "pass 668\n",
      "pass 669\n",
      "pass 670\n",
      "pass 671\n",
      "pass 672\n",
      "pass 673\n",
      "pass 674\n",
      "pass 675\n",
      "pass 676\n",
      "pass 677\n",
      "pass 678\n",
      "pass 679\n",
      "pass 680\n",
      "pass 681\n",
      "pass 682\n",
      "pass 683\n",
      "pass 684\n",
      "pass 685\n",
      "pass 686\n",
      "pass 687\n",
      "pass 688\n",
      "pass 689\n",
      "pass 690\n",
      "pass 691\n",
      "pass 692\n",
      "pass 693\n",
      "pass 694\n",
      "pass 695\n",
      "pass 696\n",
      "pass 697\n",
      "pass 698\n",
      "pass 699\n",
      "pass 700\n",
      "pass 701\n",
      "pass 702\n",
      "pass 703\n",
      "pass 704\n",
      "pass 705\n",
      "pass 706\n",
      "pass 707\n",
      "pass 708\n",
      "pass 709\n",
      "pass 710\n",
      "pass 711\n",
      "pass 712\n",
      "pass 713\n",
      "pass 714\n",
      "pass 715\n",
      "pass 716\n",
      "pass 717\n",
      "pass 718\n",
      "pass 719\n",
      "pass 720\n",
      "pass 721\n",
      "pass 722\n",
      "pass 723\n",
      "pass 724\n",
      "pass 725\n",
      "pass 726\n",
      "pass 727\n",
      "pass 728\n",
      "pass 729\n",
      "pass 730\n",
      "pass 731\n",
      "pass 732\n",
      "pass 733\n",
      "pass 734\n",
      "pass 735\n",
      "pass 736\n",
      "pass 737\n",
      "pass 738\n",
      "pass 739\n",
      "pass 740\n",
      "pass 741\n",
      "pass 742\n",
      "pass 743\n",
      "pass 744\n",
      "pass 745\n",
      "pass 746\n",
      "pass 747\n",
      "pass 748\n",
      "pass 749\n",
      "pass 750\n",
      "pass 751\n",
      "pass 752\n",
      "pass 753\n",
      "pass 754\n",
      "pass 755\n",
      "pass 756\n",
      "pass 757\n",
      "pass 758\n",
      "pass 759\n",
      "pass 760\n",
      "pass 761\n",
      "pass 762\n",
      "pass 763\n",
      "pass 764\n",
      "pass 765\n",
      "pass 766\n",
      "pass 767\n",
      "pass 768\n",
      "pass 769\n",
      "pass 770\n",
      "pass 771\n",
      "pass 772\n",
      "pass 773\n",
      "pass 774\n",
      "pass 775\n",
      "pass 776\n",
      "pass 777\n",
      "pass 778\n",
      "pass 779\n",
      "pass 780\n",
      "pass 781\n",
      "pass 782\n",
      "pass 783\n",
      "pass 784\n",
      "pass 785\n",
      "pass 786\n",
      "pass 787\n",
      "pass 788\n",
      "pass 789\n",
      "pass 790\n",
      "pass 791\n",
      "pass 792\n",
      "pass 793\n",
      "pass 794\n",
      "pass 795\n",
      "pass 796\n",
      "pass 797\n",
      "pass 798\n",
      "pass 799\n",
      "pass 800\n",
      "pass 801\n",
      "pass 802\n",
      "pass 803\n",
      "pass 804\n",
      "pass 805\n",
      "pass 806\n",
      "pass 807\n",
      "pass 808\n",
      "pass 809\n",
      "pass 810\n",
      "pass 811\n",
      "pass 812\n",
      "pass 813\n",
      "pass 814\n",
      "pass 815\n",
      "pass 816\n",
      "pass 817\n",
      "pass 818\n",
      "pass 819\n",
      "pass 820\n",
      "pass 821\n",
      "pass 822\n",
      "pass 823\n",
      "pass 824\n",
      "pass 825\n",
      "pass 826\n",
      "pass 827\n",
      "pass 828\n",
      "pass 829\n",
      "pass 830\n",
      "pass 831\n",
      "pass 832\n",
      "pass 833\n",
      "pass 834\n",
      "pass 835\n",
      "pass 836\n",
      "pass 837\n",
      "pass 838\n",
      "pass 839\n",
      "pass 840\n",
      "pass 841\n",
      "pass 842\n",
      "pass 843\n",
      "pass 844\n",
      "pass 845\n",
      "pass 846\n",
      "pass 847\n",
      "pass 848\n",
      "pass 849\n",
      "pass 850\n",
      "pass 851\n",
      "pass 852\n",
      "pass 853\n",
      "pass 854\n",
      "pass 855\n",
      "pass 856\n",
      "pass 857\n",
      "pass 858\n",
      "pass 859\n",
      "pass 860\n",
      "pass 861\n",
      "pass 862\n",
      "pass 863\n",
      "pass 864\n",
      "pass 865\n",
      "pass 866\n",
      "pass 867\n",
      "pass 868\n",
      "pass 869\n",
      "pass 870\n",
      "pass 871\n",
      "pass 872\n",
      "pass 873\n",
      "pass 874\n",
      "pass 875\n",
      "pass 876\n",
      "pass 877\n",
      "pass 878\n",
      "pass 879\n",
      "pass 880\n",
      "pass 881\n",
      "pass 882\n",
      "pass 883\n",
      "pass 884\n",
      "pass 885\n",
      "pass 886\n",
      "pass 887\n",
      "pass 888\n",
      "pass 889\n",
      "pass 890\n",
      "pass 891\n",
      "pass 892\n",
      "pass 893\n",
      "pass 894\n",
      "pass 895\n",
      "pass 896\n",
      "pass 897\n",
      "pass 898\n",
      "pass 899\n",
      "pass 900\n",
      "pass 901\n",
      "pass 902\n",
      "pass 903\n",
      "pass 904\n",
      "pass 905\n",
      "pass 906\n",
      "pass 907\n",
      "pass 908\n",
      "pass 909\n",
      "pass 910\n",
      "pass 911\n",
      "pass 912\n",
      "pass 913\n",
      "pass 914\n",
      "pass 915\n",
      "pass 916\n",
      "pass 917\n",
      "pass 918\n",
      "pass 919\n",
      "pass 920\n",
      "pass 921\n",
      "pass 922\n",
      "pass 923\n",
      "pass 924\n",
      "pass 925\n",
      "pass 926\n",
      "pass 927\n",
      "pass 928\n",
      "pass 929\n",
      "pass 930\n",
      "pass 931\n",
      "pass 932\n",
      "pass 933\n",
      "pass 934\n",
      "pass 935\n",
      "pass 936\n",
      "pass 937\n",
      "pass 938\n",
      "pass 939\n",
      "pass 940\n",
      "pass 941\n",
      "pass 942\n",
      "pass 943\n",
      "pass 944\n",
      "pass 945\n",
      "pass 946\n",
      "pass 947\n",
      "pass 948\n",
      "pass 949\n",
      "pass 950\n",
      "pass 951\n",
      "pass 952\n",
      "pass 953\n",
      "pass 954\n",
      "pass 955\n",
      "pass 956\n",
      "pass 957\n",
      "pass 958\n",
      "pass 959\n",
      "pass 960\n",
      "pass 961\n",
      "pass 962\n",
      "pass 963\n",
      "pass 964\n",
      "pass 965\n",
      "pass 966\n",
      "pass 967\n",
      "pass 968\n",
      "pass 969\n",
      "pass 970\n",
      "pass 971\n",
      "pass 972\n",
      "pass 973\n",
      "pass 974\n",
      "pass 975\n",
      "pass 976\n",
      "pass 977\n",
      "pass 978\n",
      "pass 979\n",
      "pass 980\n",
      "pass 981\n",
      "pass 982\n",
      "pass 983\n",
      "pass 984\n",
      "pass 985\n",
      "pass 986\n",
      "pass 987\n",
      "pass 988\n",
      "pass 989\n",
      "pass 990\n",
      "pass 991\n",
      "pass 992\n",
      "pass 993\n",
      "pass 994\n",
      "pass 995\n",
      "pass 996\n",
      "pass 997\n",
      "pass 998\n",
      "pass 999\n",
      "pass 1000\n",
      "pass 1001\n",
      "pass 1002\n",
      "pass 1003\n",
      "pass 1004\n",
      "pass 1005\n",
      "pass 1006\n",
      "pass 1007\n",
      "pass 1008\n",
      "pass 1009\n",
      "pass 1010\n",
      "pass 1011\n",
      "pass 1012\n",
      "pass 1013\n",
      "pass 1014\n",
      "pass 1015\n",
      "pass 1016\n",
      "pass 1017\n",
      "pass 1018\n",
      "pass 1019\n",
      "pass 1020\n",
      "pass 1021\n",
      "pass 1022\n",
      "pass 1023\n",
      "pass 1024\n",
      "pass 1025\n",
      "pass 1026\n",
      "pass 1027\n",
      "pass 1028\n",
      "pass 1029\n",
      "pass 1030\n",
      "pass 1031\n",
      "pass 1032\n",
      "pass 1033\n",
      "pass 1034\n",
      "pass 1035\n",
      "pass 1036\n",
      "pass 1037\n",
      "pass 1038\n",
      "pass 1039\n",
      "pass 1040\n",
      "pass 1041\n",
      "pass 1042\n",
      "pass 1043\n",
      "pass 1044\n",
      "pass 1045\n",
      "pass 1046\n",
      "pass 1047\n",
      "pass 1048\n",
      "pass 1049\n",
      "pass 1050\n",
      "pass 1051\n",
      "pass 1052\n",
      "pass 1053\n",
      "pass 1054\n",
      "pass 1055\n",
      "pass 1056\n",
      "pass 1057\n",
      "pass 1058\n",
      "pass 1059\n",
      "pass 1060\n",
      "pass 1061\n",
      "pass 1062\n",
      "pass 1063\n",
      "pass 1064\n",
      "pass 1065\n",
      "pass 1066\n",
      "pass 1067\n",
      "pass 1068\n",
      "pass 1069\n",
      "pass 1070\n",
      "pass 1071\n",
      "pass 1072\n",
      "pass 1073\n",
      "pass 1074\n",
      "pass 1075\n",
      "pass 1076\n",
      "pass 1077\n",
      "pass 1078\n",
      "pass 1079\n",
      "pass 1080\n",
      "pass 1081\n",
      "pass 1082\n",
      "pass 1083\n",
      "pass 1084\n",
      "pass 1085\n",
      "pass 1086\n",
      "pass 1087\n",
      "pass 1088\n",
      "pass 1089\n",
      "pass 1090\n",
      "pass 1091\n",
      "pass 1092\n",
      "pass 1093\n",
      "pass 1094\n",
      "pass 1095\n",
      "pass 1096\n",
      "pass 1097\n",
      "pass 1098\n",
      "pass 1099\n",
      "pass 1100\n",
      "pass 1101\n",
      "pass 1102\n",
      "pass 1103\n",
      "pass 1104\n",
      "pass 1105\n",
      "pass 1106\n",
      "pass 1107\n",
      "pass 1108\n",
      "pass 1109\n",
      "pass 1110\n",
      "pass 1111\n",
      "pass 1112\n",
      "pass 1113\n",
      "pass 1114\n",
      "pass 1115\n",
      "pass 1116\n",
      "pass 1117\n",
      "pass 1118\n",
      "pass 1119\n",
      "pass 1120\n",
      "pass 1121\n",
      "pass 1122\n",
      "pass 1123\n",
      "pass 1124\n",
      "pass 1125\n",
      "pass 1126\n",
      "pass 1127\n",
      "pass 1128\n",
      "pass 1129\n",
      "pass 1130\n",
      "pass 1131\n",
      "pass 1132\n",
      "pass 1133\n",
      "pass 1134\n",
      "pass 1135\n",
      "pass 1136\n",
      "pass 1137\n",
      "pass 1138\n",
      "pass 1139\n",
      "pass 1140\n",
      "pass 1141\n",
      "pass 1142\n",
      "pass 1143\n",
      "pass 1144\n",
      "pass 1145\n",
      "pass 1146\n",
      "pass 1147\n",
      "pass 1148\n",
      "pass 1149\n",
      "pass 1150\n",
      "pass 1151\n",
      "pass 1152\n",
      "pass 1153\n",
      "pass 1154\n",
      "pass 1155\n",
      "pass 1156\n",
      "pass 1157\n",
      "pass 1158\n",
      "pass 1159\n",
      "pass 1160\n",
      "pass 1161\n",
      "pass 1162\n",
      "pass 1163\n",
      "pass 1164\n",
      "pass 1165\n",
      "pass 1166\n",
      "pass 1167\n",
      "pass 1168\n",
      "pass 1169\n",
      "pass 1170\n",
      "pass 1171\n",
      "pass 1172\n",
      "pass 1173\n",
      "pass 1174\n",
      "pass 1175\n",
      "pass 1176\n",
      "pass 1177\n",
      "pass 1178\n",
      "pass 1179\n",
      "pass 1180\n",
      "pass 1181\n",
      "pass 1182\n",
      "pass 1183\n",
      "pass 1184\n",
      "pass 1185\n",
      "pass 1186\n",
      "pass 1187\n",
      "pass 1188\n",
      "pass 1189\n",
      "pass 1190\n",
      "pass 1191\n",
      "pass 1192\n",
      "pass 1193\n",
      "pass 1194\n",
      "pass 1195\n",
      "pass 1196\n",
      "pass 1197\n",
      "pass 1198\n",
      "pass 1199\n",
      "pass 1200\n",
      "pass 1201\n",
      "pass 1202\n",
      "pass 1203\n",
      "pass 1204\n",
      "pass 1205\n",
      "pass 1206\n",
      "pass 1207\n",
      "pass 1208\n",
      "pass 1209\n",
      "pass 1210\n",
      "pass 1211\n",
      "pass 1212\n",
      "pass 1213\n",
      "pass 1214\n",
      "pass 1215\n",
      "pass 1216\n",
      "pass 1217\n",
      "pass 1218\n",
      "pass 1219\n",
      "pass 1220\n",
      "pass 1221\n",
      "pass 1222\n",
      "pass 1223\n",
      "pass 1224\n",
      "pass 1225\n",
      "pass 1226\n",
      "pass 1227\n",
      "pass 1228\n",
      "pass 1229\n",
      "pass 1230\n",
      "pass 1231\n",
      "pass 1232\n",
      "pass 1233\n",
      "pass 1234\n",
      "pass 1235\n",
      "pass 1236\n",
      "pass 1237\n",
      "pass 1238\n",
      "pass 1239\n",
      "pass 1240\n",
      "pass 1241\n",
      "pass 1242\n",
      "pass 1243\n",
      "pass 1244\n",
      "pass 1245\n",
      "pass 1246\n",
      "pass 1247\n",
      "pass 1248\n",
      "pass 1249\n",
      "pass 1250\n",
      "pass 1251\n",
      "pass 1252\n",
      "pass 1253\n",
      "pass 1254\n",
      "pass 1255\n",
      "pass 1256\n",
      "pass 1257\n",
      "pass 1258\n",
      "pass 1259\n",
      "pass 1260\n",
      "pass 1261\n",
      "pass 1262\n",
      "pass 1263\n",
      "pass 1264\n",
      "pass 1265\n",
      "pass 1266\n",
      "pass 1267\n",
      "pass 1268\n",
      "pass 1269\n",
      "pass 1270\n",
      "pass 1271\n",
      "pass 1272\n",
      "pass 1273\n",
      "pass 1274\n",
      "pass 1275\n",
      "pass 1276\n",
      "pass 1277\n",
      "pass 1278\n",
      "pass 1279\n",
      "pass 1280\n"
     ]
    }
   ],
   "source": [
    "#process task 5 with qa\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "\n",
    "path = './data/backup/task5_w_qa.jsonl'\n",
    "data = []\n",
    "with open(path, 'r') as file:\n",
    "    for line in file:\n",
    "        newline = eval(line)\n",
    "        data.append(newline)\n",
    "file.close()\n",
    "\n",
    "conversations = []\n",
    "patient_infos = []\n",
    "questions = []\n",
    "answers = []\n",
    "cnt = 0\n",
    "for item in data:\n",
    "    question_answer = item[1]['value']\n",
    "    patient_info = item[0]['value'].replace('问题：'+item[1]['value'], \"\")\n",
    "    question_answer = question_answer.replace('#', '').replace('*', '')\n",
    "    qas = re.split('问题.*：|问题.*:|问题:|问题：|答案', question_answer)\n",
    "    \n",
    "    new_qas = []\n",
    "    for i, qa in enumerate(qas):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if i == len(qas)-1:\n",
    "            new_qas.append(qa)\n",
    "            break\n",
    "        if '？' in qa or '?' in qa:\n",
    "            new_qas.append(qa)\n",
    "        else:\n",
    "            if '？' in qas[i+1] or '?' in qas[i+1]:\n",
    "                new_qas.append(qa)\n",
    "            else:\n",
    "                qas[i+1] = qa + qas[i+1]\n",
    "                # continue\n",
    "    \n",
    "    if len(new_qas) == 6:\n",
    "        question1 = new_qas[0]\n",
    "        question2 = new_qas[2]\n",
    "        question3 = new_qas[4]\n",
    "        \n",
    "        answer1 = new_qas[1]\n",
    "        answer2 = new_qas[3]\n",
    "        answer3 = new_qas[5]\n",
    "    else:\n",
    "        cnt += 1\n",
    "        print('pass {}'.format(cnt))\n",
    "        continue\n",
    "    \n",
    "    conversation = []\n",
    "    conversation.append({'from': 'human', 'value': '{}\\n 问题：{}'.format(patient_info, question1)})\n",
    "    conversation.append({'from': 'gpt', 'value': answer1})\n",
    "    conversations.append({'conversations': conversation})\n",
    "    \n",
    "    conversation = []\n",
    "    conversation.append({'from': 'human', 'value': '{}\\n 问题：{}'.format(patient_info, question2)})\n",
    "    conversation.append({'from': 'gpt', 'value': answer2})\n",
    "    conversations.append({'conversations': conversation})\n",
    "    \n",
    "    conversation = []\n",
    "    conversation.append({'from': 'human', 'value': '{}\\n 问题：{}'.format(patient_info, question3)})\n",
    "    conversation.append({'from': 'gpt', 'value': answer3})\n",
    "    conversations.append({'conversations': conversation})\n",
    "    \n",
    "random.shuffle(conversations)\n",
    "with open(r'D:\\work\\code\\psychgpt\\sft\\data\\task5.jsonl', 'w') as file:\n",
    "    for item in conversations:\n",
    "        # 将每个字典转换为JSON字符串并写入文件\n",
    "        json_str = json.dumps(item, ensure_ascii=False)\n",
    "        file.write(json_str + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# F30-F33\n",
    "path_f3x_sc = r\"D:\\work\\data_process\\F30-F33\\首程.xlsx\"\n",
    "path_f3x_bc = r\"D:\\work\\data_process\\F30-F33\\病程(2022-2024).xlsx\"\n",
    "\n",
    "# F20-F29\n",
    "path_f2x_sc = r\"D:\\work\\data_process\\F20-F29\\F20-F29首程.xlsx\"\n",
    "path_f2x_bc = r\"D:\\work\\data_process\\F20-F29\\F20-F29病程.xlsx\"\n",
    "\n",
    "\n",
    "# Task1-summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

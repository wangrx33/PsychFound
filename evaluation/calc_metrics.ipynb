{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QC\n",
    "import json\n",
    "\n",
    "nshot = 0\n",
    "for task in ['1','2','3','4','5','5_qa_split','5_mc_split','0_knowledge','0_mc_CMExam','0_lt_split']:\n",
    "\n",
    "    print('-'*25,task,'-'*25)\n",
    "    for model in ['psychfound']:\n",
    "        if task == '5': nshot=0\n",
    "        output_pth = './result/API/{}shot/task{}_{}.json'.format(nshot,task,model)\n",
    "        lines = []\n",
    "        id = 1\n",
    "        total = 0\n",
    "        failed = []\n",
    "        try:\n",
    "            with open(output_pth, 'r', encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    total += 1\n",
    "                    data = json.loads(line)\n",
    "                    answer_key = [key for key in data.keys() if 'answer_' in key][0]\n",
    "                    if data[answer_key] == 'API调用失败' or data[answer_key] == 'failed':\n",
    "                        failed.append(id)\n",
    "                    id += 1\n",
    "            print(model.ljust(20),'\\t',total,'\\t',len(failed),'\\t',failed)\n",
    "        except:\n",
    "            print(output_pth,'not exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### gathering ans for task5 qa and mc\n",
    "\n",
    "import os\n",
    "import json \n",
    "\n",
    "\n",
    "def form_ans(ans_list):\n",
    "    ans = ''\n",
    "    for i in range(len(ans_list)):\n",
    "        ans += f'[答案{i+1}]'+ans_list[i].strip('\\n') + '\\n'\n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "root_path = './result/API/'\n",
    "\n",
    "\n",
    "for shot in ['0']:\n",
    "    for task in ['task5_mc_split','task5_qa_split']:\n",
    "            \n",
    "            for model in ['psychfound']:\n",
    "                ans_fail_cnt = 0\n",
    "                file_path = os.path.join(root_path,'{}shot/{}_{}.json'.format(shot,task,model))\n",
    "                answers = []\n",
    "                # question_dict = {}\n",
    "                answer_dict = {}\n",
    "                reasoning_dict = {}\n",
    "                with open(file_path,'r',encoding='utf-8') as f:\n",
    "                    for line in f.readlines():\n",
    "                        answers.append(json.loads(line))\n",
    "                print(len(answers))\n",
    "                for ans in answers:\n",
    "                    # print(ans['id'])\n",
    "                    reasoning_ans = ans['answer_0']\n",
    "                    reasoning = reasoning_ans.split('</think>')[0]\n",
    "                    if '</think>' in reasoning_ans:\n",
    "                        ans['answer_0'] = reasoning_ans.split('</think>')[-1].replace('<answer>','').replace('</answer>','')\n",
    "                    elif '<answer>' in reasoning_ans:\n",
    "                        ans['answer_0'] = reasoning_ans.split('<answer>')[-1]\n",
    "                    else:\n",
    "                        # print(reasoning_ans)\n",
    "                        ans_fail_cnt += 1\n",
    "                        ans['answer_0'] = reasoning_ans\n",
    "                        \n",
    "\n",
    "                    if task == 'task5_qa_split':\n",
    "                        ans['id'] = ans['id'].split('-')[0]+'-'+ str(int(ans['id'].split('-')[-1])//3)\n",
    "                    if ans['id'] in answer_dict.keys():\n",
    "                        answer_dict[ans['id']].append(ans['answer_0'])\n",
    "                        reasoning_dict[ans['id']].append(reasoning)\n",
    "                    else:\n",
    "                         answer_dict[ans['id']] = [ans['answer_0']]\n",
    "                         reasoning_dict[ans['id']]=[reasoning]\n",
    "                        #  question_dict[ans['id']] = [ans['query'].split('[问题]')[-1]]\n",
    "\n",
    "                if task == 'task5_qa_split':\n",
    "                    ref_path = os.path.join(root_path,'{}shot/{}_{}.json'.format(shot,'task5_qa','gpt-4'))\n",
    "                if task == 'task5_mc_split':\n",
    "                    ref_path = os.path.join(root_path,'{}shot/{}_{}.json'.format(shot,'task5_mc','gpt-4'))\n",
    "                \n",
    "                ref_answers = []\n",
    "                with open(ref_path,'r',encoding='utf-8') as f:\n",
    "                     for line in f.readlines():\n",
    "                        ref_answers.append(json.loads(line))\n",
    "                print(len(ref_answers))\n",
    "\n",
    "                for i in range(len(ref_answers)):\n",
    "                    ref_answers[i]['answer_0'] = form_ans(answer_dict[ref_answers[i]['id']])\n",
    "                    ref_answers[i]['reasoning_0'] = reasoning_dict[ref_answers[i]['id']]\n",
    "                    \n",
    "                # print(ref_answers[0])\n",
    "                    # print(ans)\n",
    "                    # print(answer_dict)\n",
    "                \n",
    "                if task == 'task5_qa_split':\n",
    "                    output_pth = os.path.join(root_path,'{}shot/{}_{}.json'.format(shot,'task5_qa',model))\n",
    "                if task == 'task5_mc_split':\n",
    "                    output_pth = os.path.join(root_path,'{}shot/{}_{}.json'.format(shot,'task5_mc',model))\n",
    "\n",
    "                writer = open(output_pth, \"w\", encoding='utf-8')\n",
    "                for line in ref_answers:\n",
    "                    writer.write(json.dumps(line, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "                print('output to', output_pth)\n",
    "                print('failed ans cnt', ans_fail_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reformat json\n",
    "import json\n",
    "import os\n",
    "nshot = 0\n",
    "\n",
    "os.makedirs('./result-refined/API/0shot',exist_ok=True)\n",
    "\n",
    "for task in ['1','2','3','4','5','5_qa','5_mc','0_mc_CMExam','0_lt_split','0_knowledge']:\n",
    "\n",
    "    for model in ['psychfound']:\n",
    "        if task == '5' or task == '5_exam': nshot = 0\n",
    "        output_pth = './result/API/{}shot/task{}_{}.json'.format(nshot,task,model)\n",
    "        lines = []\n",
    "        try:\n",
    "            with open(output_pth, 'r', encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    lines.append(json.loads(line))\n",
    "        except:\n",
    "            print(output_pth,'not exist')\n",
    "            continue\n",
    "        with open(output_pth.replace('result','result-refined'), 'w', encoding=\"utf-8\") as f:\n",
    "            json.dump(lines, f, ensure_ascii=False, indent=4)\n",
    "        output_pth = output_pth.replace('result','result-refined')\n",
    "        print(f'output to {output_pth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split reasoning and ans content\n",
    "import os\n",
    "import json\n",
    "\n",
    "for task in ['1','2','3','4','0_knowledge','0_lt_split','0_mc_CMExam']:\n",
    "\n",
    "    print('='*50,task)\n",
    "    for model in ['psychfound']:\n",
    "        new_data = []\n",
    "        with open('./result-refined/API/0shot/task{}_{}.json'.format(task,model),'r', encoding='utf-8') as f:    \n",
    "            data = json.load(f)\n",
    "            cut_cnt = 0\n",
    "            for adata in data:\n",
    "                # print(adata['answer_0'])\n",
    "                if '<think>' in adata['answer_0'] or '</think>' in adata['answer_0']:\n",
    "                    if '</think>' in adata['answer_0']:\n",
    "                        # reasoning = adata['answer_0'].split('<think>')[-1].split('</think>')[0]\n",
    "                        reasoning = '</think>'.join(adata['answer_0'].split('</think>')[:-1])\n",
    "                        answer = adata['answer_0'].split('</think>')[-1]\n",
    "                    else:\n",
    "                        if '<answer>' in adata['answer_0']:\n",
    "                            reasoning = '<answer>'.join(adata['answer_0'].split('<answer>')[:-1])\n",
    "                            answer = adata['answer_0'].split('<answer>')[-1]\n",
    "                        else:\n",
    "                            reasoning = adata['answer_0']\n",
    "                            answer = '<think>'.join(adata['answer_0'].split('<think>')[:-1])\n",
    "                            # print(reasoning)\n",
    "                            cut_cnt += 1\n",
    "                            print(adata['id'])\n",
    "\n",
    "                    # if adata['id'] == \"Anding-clinical-21\":\n",
    "                    #     a = 1\n",
    "                    if len(answer.replace('\\n','').replace('<answer>','').replace('</answer>','').replace(' ','')) < 10 and task in ['1','2','3','4']:\n",
    "                        answer = reasoning + answer\n",
    "                    # answer = answer.replace('<answer>','').replace('</answer>','')\n",
    "\n",
    "                    answer = answer.replace('<think>','').replace('</think>','').replace('<answer>','').replace('</answer>','')\n",
    "                    while '\\n\\n' in answer:\n",
    "                        answer = answer.replace('\\n\\n','\\n').strip('\\n')\n",
    "\n",
    "                    adata['answer_0'] = answer\n",
    "                    adata['reasoning_0'] = reasoning\n",
    "                else:\n",
    "                    adata=adata\n",
    "                new_data.append(adata)\n",
    "                # print(adata['answer_0'])\n",
    "                # break\n",
    "            f.close()\n",
    "        with open('./result-refined/API/0shot/task{}_{}.json'.format(task,model),'w', encoding='utf-8') as f:\n",
    "            json.dump(new_data, f, ensure_ascii=False, indent=4)\n",
    "        print('reasoning failed cnt:',cut_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check num of refined ans\n",
    "\n",
    "nshot = 0\n",
    "\n",
    "for task in ['1','2','3','4','5_qa','5_mc','0_lt_split','0_knowledge','0_mc_CMExam']:\n",
    "    print('-'*25,task,'-'*25)\n",
    "\n",
    "    for model in ['psychfound']:\n",
    "    \n",
    "        failed = []\n",
    "        if task == '5_qa' or task == '5_mc' or task == '0_lt_split' or task == '0_knowledge' or task == '0_mc_CMExam': nshot = 0\n",
    "        \n",
    "        output_pth = '{}/{}shot/task{}_{}.json'.format('result-refined/API',nshot,task,model)\n",
    "        lines = []\n",
    "        try:\n",
    "            with open(output_pth, \"r\", encoding=\"utf-8\") as f:\n",
    "                sub_answers = json.load(f)\n",
    "            for ans in sub_answers:\n",
    "                answer_key = [key for key in ans.keys() if 'answer_' in key][0]\n",
    "                id = ans['id']\n",
    "                if ans[answer_key] == 'API调用失败':\n",
    "                    failed.append(id)\n",
    "            print(model.ljust(30),'\\t',len(sub_answers),'\\t',len(failed),'\\t',failed)\n",
    "        except:\n",
    "            print(output_pth,'not exist')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc NER Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calc ner \n",
    "### First: Set kernal to tf1!\n",
    "# requirements\n",
    "# Keras==2.2.4\n",
    "# matplotlib==3.4.0\n",
    "# pandas==1.2.3\n",
    "# tensorflow==1.14.0\n",
    "# tqdm==4.61.2\n",
    "\n",
    "import os\n",
    "nshot = 0\n",
    "for task in [1,3,'5_qa']:\n",
    "    print('-'*50,'task{}'.format(task),'-'*50)\n",
    "    for model in ['psychfound']:  \n",
    "        print(model)\n",
    "        if task == 5:\n",
    "            nshot=0\n",
    "\n",
    "        ans_path = './result-refined/API/{}shot/task{}_{}.json'.format(nshot,task,model)\n",
    "        dir_out = './src/ner_result/PsychClinical/{}shot/{}/task{}'.format(nshot,model,task)\n",
    "\n",
    "\n",
    "        if not os.path.exists(ans_path):\n",
    "            print('Error:',ans_path,'not exist!!!')\n",
    "            continue\n",
    "\n",
    "        ## 若想要生成cot格式的数据，加上--use_cot \\ 目前只有Exam的选择题可用\n",
    "        os.system('conda activate tf1')\n",
    "        os.system('python -u ./chinese_medical_ner/ccksyidu4k-ner-roformer/evaluate_ner.py \\\n",
    "            --ans_path={} \\\n",
    "            --dir_out={} \\\n",
    "            > output_calc_ner.log 2>&1'.format(ans_path,dir_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check ner result\n",
    "import numpy as np\n",
    "data = np.load('./src/ner_result/PsychClinical/0shot/psychfound/task1/ner_cls_result.npy',allow_pickle=True)\n",
    "data1 = np.load('./src/ner_result/PsychClinical/0shot/psychfound/task1/ner_result.npy',allow_pickle=True)\n",
    "print(len(data))\n",
    "print(data[0])\n",
    "print(data1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calc MNER-Precision Recall F1-score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model = 'psychfound'\n",
    "ner_path = './src/ner_result/PsychClinical/0shot/{}/task3/ner_result.npy'.format(model)\n",
    "ner_result = np.load(ner_path,allow_pickle=True)\n",
    "# print(ner_result)\n",
    "\n",
    "\n",
    "p_list,r_list,f_list = [],[],[]\n",
    "\n",
    "for result in ner_result:\n",
    "    tgt_list,out_list = result\n",
    "\n",
    "    # tgt_list = set(tgt_list)\n",
    "    # out_list = set(out_list)\n",
    "    \n",
    "    intersection_precision = 0\n",
    "    intersection_recall = 0\n",
    "\n",
    "    for tgt in tgt_list:\n",
    "        for out in out_list:\n",
    "            if (tgt in out) or (out in tgt):\n",
    "                intersection_recall += 1\n",
    "    \n",
    "    for out in out_list:\n",
    "        for tgt in tgt_list:\n",
    "            if (tgt in out) or (out in tgt):\n",
    "                intersection_precision += 1\n",
    "\n",
    "    intersection = set(tgt_list).intersection(set(out_list))\n",
    "\n",
    "\n",
    "    if not out_list or not tgt_list:\n",
    "        continue\n",
    "\n",
    "    # precision\n",
    "    precision = intersection_precision / len(out_list) if out_list else 0\n",
    "\n",
    "    # recall\n",
    "    recall = intersection_recall / len(tgt_list) if tgt_list else 0\n",
    "\n",
    "    # F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "\n",
    "    p_list.append(precision)\n",
    "    r_list.append(recall)\n",
    "    f_list.append(f1_score)\n",
    "\n",
    "p_list = np.array(p_list)\n",
    "r_list = np.array(r_list)\n",
    "f_list = np.array(f_list)\n",
    "\n",
    "print(np.mean(p_list),',',np.std(p_list))\n",
    "print(np.mean(r_list),',',np.std(r_list))\n",
    "print(np.mean(f_list),',',np.std(f_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### calc MNER-BERTScore\n",
    "# ### First: Set kernal to py310\n",
    "\n",
    "# ## calc with cpu\n",
    "# ## try\n",
    "# import time\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # load model\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"F:/LM/model_zoo/bert-base-chinese\") ## \"bert-base-chinese\"\n",
    "# bert_model = BertModel.from_pretrained(\"F:/LM/model_zoo/bert-base-chinese\")\n",
    "\n",
    "\n",
    "# tgt_list = ['乏力感', '厌世', '躯体不适', '社会功能严重受损', '兴趣减退', '言行紊乱', '脑器质性疾病', '情绪低落', '精神障碍', '情绪差伴躯体不适', '焦虑', '自责']\n",
    "# out_list = ['认知行为治疗', '与家人交流障碍', '偶有轻生想法', '长期适应性障碍', '利培酮', '心理治疗', '发呆', '独处时感到被支配', '沉迷学佛后出现精神异常', '与家人交流困难', '急性而短暂的精神病性障碍', '兴趣减退', '有被害妄想和攻击行为', '言语紊乱', '自知力可', '攻击行为', '心脏', '肝脏', '反应慢', '持续的情绪低落', '沉迷学佛', '氢溴酸西酞普兰', '无法胜任家务', '情绪低落', '急性起病', '被害妄想', '社会功能受损', '重度抑郁发作']\n",
    "# print(len(tgt_list))\n",
    "# print(len(out_list))\n",
    "\n",
    "# def get_word_embedding(word):\n",
    "   \n",
    "#     input_ids = tokenizer.encode(word, add_special_tokens=True, return_tensors='pt')\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         output = bert_model(input_ids)\n",
    "    \n",
    "#     return output.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "\n",
    "# def calculate_similarity_matrix(words_list1, words_list2):\n",
    "#     if len(words_list1) > 0 and len(words_list2) > 0:\n",
    "#         embeddings1 = np.array([get_word_embedding(word) for word in words_list1])\n",
    "#         embeddings2 = np.array([get_word_embedding(word) for word in words_list2])\n",
    "        \n",
    "#         # 计算余弦相似性矩阵\n",
    "#         similarity_matrix = cosine_similarity(embeddings1.reshape(embeddings1.shape[0],-1), embeddings2.reshape(embeddings2.shape[0],-1))\n",
    "#     else:\n",
    "#         similarity_matrix = np.zeros((2,2))\n",
    "#     return similarity_matrix\n",
    "\n",
    "# time1 = time.time()\n",
    "# similarity_matrix = calculate_similarity_matrix(tgt_list, out_list)\n",
    "# time2 = time.time()\n",
    "# time_cost = time2-time1\n",
    "# print(time_cost)\n",
    "\n",
    "# print(similarity_matrix)\n",
    "# print(np.max(np.array(similarity_matrix),axis=1).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import time\n",
    "from transformers import BertTokenizer, BertModel,AlbertTokenizer,AlbertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# https://huggingface.co/iioSnail/bert-base-chinese-medical-ner\n",
    "tokenizer = BertTokenizer.from_pretrained(\"iioSnail/bert-base-chinese-medical-ner\")\n",
    "bert_model = BertModel.from_pretrained(\"iioSnail/bert-base-chinese-medical-ner\")\n",
    "\n",
    "\n",
    "# load model to gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model.to(device)\n",
    "\n",
    "\n",
    "tgt_list = ['乏力感', '厌世', '躯体不适', '社会功能严重受损', '兴趣减退', '言行紊乱', '脑器质性疾病', '情绪低落', '精神障碍', '情绪差伴躯体不适', '焦虑', '自责']\n",
    "out_list = ['认知行为治疗', '与家人交流障碍', '偶有轻生想法', '长期适应性障碍', '利培酮', '心理治疗', '发呆', '独处时感到被支配', '沉迷学佛后出现精神异常', '与家人交流困难', '急性而短暂的精神病性障碍', '兴趣减退', '有被害妄想和攻击行为', '言语紊乱', '自知力可', '攻击行为', '心脏', '肝脏', '反应慢', '持续的情绪低落', '沉迷学佛', '氢溴酸西酞普兰', '无法胜任家务', '情绪低落', '急性起病', '被害妄想', '社会功能受损', '重度抑郁发作']\n",
    "print(len(tgt_list))\n",
    "print(len(out_list))\n",
    "\n",
    "# 批量获取词向量\n",
    "def get_word_embeddings(words, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(words), batch_size):\n",
    "        batch = words[i: i + batch_size]\n",
    "        # 对单词进行编码\n",
    "        input_ids = tokenizer(batch, add_special_tokens=True, return_tensors='pt', padding=True, truncation=True)\n",
    "        input_ids = {k: v.to(device) for k, v in input_ids.items()}\n",
    "        # 获取词向量\n",
    "        with torch.no_grad():\n",
    "            output = bert_model(**input_ids)\n",
    "        # 使用[CLS]标记的向量作为句子向量\n",
    "        embeddings = output.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embeddings.extend(embeddings)\n",
    "        # 及时释放显存\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "    return np.array(all_embeddings)\n",
    "\n",
    "# 计算相似性矩阵\n",
    "def calculate_similarity_matrix(words_list1, words_list2):\n",
    "    if len(words_list1) > 0 and len(words_list2) > 0:\n",
    "        embeddings1 = get_word_embeddings(words_list1)\n",
    "        embeddings2 = get_word_embeddings(words_list2)\n",
    "        \n",
    "        # 计算余弦相似性矩阵\n",
    "        similarity_matrix = cosine_similarity(embeddings1, embeddings2)\n",
    "    else:\n",
    "        similarity_matrix = np.zeros((2,2))\n",
    "    return similarity_matrix\n",
    "\n",
    "time1 = time.time()\n",
    "# 计算tgt和out列表的相似性矩阵\n",
    "similarity_matrix = calculate_similarity_matrix(tgt_list, out_list)\n",
    "time2 = time.time()\n",
    "time_cost = time2 - time1\n",
    "print(time_cost)\n",
    "\n",
    "# 打印相似性矩阵\n",
    "print(similarity_matrix)\n",
    "print(np.max(np.array(similarity_matrix), axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calc MNER-BERTScore\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "nshot = 0\n",
    "for task in [1,3,'5_qa']:\n",
    "\n",
    "    print('-'*50,'task{}'.format(task),'-'*50)\n",
    "    for model in ['psychfound']:\n",
    "    \n",
    "        print(model)\n",
    "        if task == 5:\n",
    "            nshot=0\n",
    "\n",
    "        ans_path = './result-refined/API/{}shot/task{}_{}.json'.format(nshot,task,model)\n",
    "        dir_out = './src/ner_result/PsychClinical/{}shot/{}/task{}'.format(nshot,model,task)\n",
    "\n",
    "        ner_path = dir_out +'/ner_result.npy'\n",
    "\n",
    "        if not os.path.exists(ner_path):\n",
    "            print('Error:',ner_path,'not exist!!!')\n",
    "            continue\n",
    "        ner_result = np.load(ner_path,allow_pickle=True)\n",
    "        ner_scores = []\n",
    "        for tgt,out in ner_result:\n",
    "            similarity_matrix = calculate_similarity_matrix(list(set(tgt)), list(set(out)))\n",
    "            \n",
    "            # print(similarity_matrix)\n",
    "            ner_score = np.max(np.array(similarity_matrix),axis=0).mean()\n",
    "            if ner_score == 0:\n",
    "                continue\n",
    "            ner_scores.append(ner_score)\n",
    "        ner_scores_mean = np.mean(ner_scores)\n",
    "        ner_scores_std = np.std(ner_scores)\n",
    "        print('ner score:{}±{}'.format(ner_scores_mean,ner_scores_std))\n",
    "        \n",
    "        ### save\n",
    "        import json\n",
    "\n",
    "        # Load the uploaded JSON file\n",
    "        file_path = dir_out +'/metrics.json'\n",
    "\n",
    "        file_path_new = dir_out +'/metrics_new.json'\n",
    "        shutil.copyfile(file_path,file_path_new)\n",
    "\n",
    "        # Read the content of the file\n",
    "        with open(file_path_new, 'r') as file:\n",
    "            metrics = json.load(file)\n",
    "        \n",
    "        np.save(dir_out + '/MNER-BERTScore.npy',ner_scores)\n",
    "\n",
    "        # Display the content of the JSON file to understand its structure\n",
    "        metrics['NER-score'] = {'avg':float(ner_scores_mean),'std':float(ner_scores_std)}\n",
    "        with open(file_path_new, 'w') as file:\n",
    "            file.write(json.dumps(metrics))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc other score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calc BLEU ROUGE BERTScore\n",
    "# pip install evaluate\n",
    "NSHOT = 0\n",
    "import os\n",
    "\n",
    "nshot = NSHOT\n",
    "for task in [1,3,'5_qa']:\n",
    "    print('-'*50,'task{}'.format(task),'-'*50)\n",
    "\n",
    "    for model in ['psychfound']:    \n",
    "\n",
    "        print(model)\n",
    "\n",
    "        ans_path = './result-refined/API/{}shot/task{}_{}.json'.format(nshot,task,model)\n",
    "        dir_out = './result/PsychClinical/{}shot/{}_api/task{}'.format(nshot,model,task)\n",
    "\n",
    "        if not os.path.exists(ans_path):\n",
    "            print('Error:',ans_path,'not exist!!!')\n",
    "            continue\n",
    "\n",
    "        os.system('python -u ./src/calc_metrics.py \\\n",
    "            --ans_path={} \\\n",
    "            --dir_out={} \\\n",
    "            > output_calc.log 2>&1'.format(ans_path,dir_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calc Acc etc.\n",
    "\n",
    "### calc metrics\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import os\n",
    "import json \n",
    "\n",
    "NSHOT = 0\n",
    "\n",
    "## integrity\n",
    "def compute_integrity(ans):\n",
    "    cnt = 0\n",
    "    if '病程标准' in ans or '病程' in ans: cnt += 1\n",
    "    if '症状学标准' in ans or '症状标准' in ans: cnt += 1\n",
    "    if '严重程度标准' in ans or '严重标准': cnt += 1\n",
    "    if '排除标准' in ans or '排除诊断' in ans: cnt += 1\n",
    "    # if cnt/4*100 != 100:\n",
    "    #     print(ans)\n",
    "    return cnt/4*100\n",
    "\n",
    "import re\n",
    "def find_time(text):\n",
    "    # 使用正则表达式匹配时间描述\n",
    "    time_patterns = [\n",
    "        r'\\d+年',\n",
    "        r'\\d+月',\n",
    "        r'\\d+天',\n",
    "        # r'\\d+余',\n",
    "        r'\\d+余日',\n",
    "        r'\\d+余月',\n",
    "        r'\\d+余年'\n",
    "    ]\n",
    "\n",
    "    times_found = []\n",
    "    for pattern in time_patterns:\n",
    "        times_found.extend(re.findall(pattern, text))\n",
    "\n",
    "    # 去重并排序结果\n",
    "    unique_times = sorted(set(times_found))\n",
    "    return unique_times\n",
    "\n",
    "def find_des(text):\n",
    "    # 使用正则表达式匹配时间描述\n",
    "    des_patterns = [\n",
    "        r'慢性',\n",
    "        r'急性',\n",
    "        r'持续',\n",
    "        r'连续',\n",
    "        r'间断',\n",
    "        r'间歇',\n",
    "        r'亚急性',\n",
    "        r'反复',\n",
    "        r'波动',\n",
    "    ]\n",
    "\n",
    "    des_found = []\n",
    "    for pattern in des_patterns:\n",
    "        des_found.extend(re.findall(pattern, text))\n",
    "\n",
    "    # 去重并排序结果\n",
    "    unique_times = sorted(set(des_found))\n",
    "    if '急性' in unique_times and '亚急性' in unique_times:\n",
    "        unique_times = [a for a in unique_times if a != '急性']\n",
    "    \n",
    "    return unique_times\n",
    "\n",
    "import re\n",
    "def find_icd(text):\n",
    "    # text = \"患者的主要诊断是 F30.901，需要进行进一步的治疗。\"\n",
    "    icd_dict = {}\n",
    "    with open('./data/psych/icd-10.jsonl','r',encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            data = json.loads(line)\n",
    "            icd_dict[data[\"ICD-10 Name\"]] = data['ICD-10 Code']\n",
    "    icd10_codes = re.findall(r'\\bF\\d+\\.*\\d+\\b', text)\n",
    "    if len(icd10_codes) < 1:\n",
    "        find_name = ''\n",
    "        for name in icd_dict.keys():\n",
    "            if name in text and len(name) > len(find_name):\n",
    "                find_name = name\n",
    "        if find_name == '':\n",
    "            print('failed to find icd in:',text)\n",
    "        return ''\n",
    "    return icd10_codes[0]  # 输出: ['F30.901']\n",
    "\n",
    "def acc_task1(out,tgt):\n",
    "    try:\n",
    "        out_zs = out.split('主诉')[1].split('病程标准')[0].split('病例特点')[0].replace('：','').replace(':','').replace('\\n','')\n",
    "        out_zs = re.split('诊断标准|病程标准|症状学标准|症状标准|严重程度标准|严重标准|排除标准|排除诊断|病例特点',out_zs)[0]\n",
    "    except:\n",
    "        out_zs = out.split('病程标准')[0]\n",
    "        # print(out)\n",
    "    tgt_zs = tgt.split('主诉：')[1].split('病例特点')[0].replace('\\n','')\n",
    "    tgt_zs = re.split('诊断标准|病程标准|症状学标准|症状标准|严重程度标准|严重标准|排除标准|排除诊断|病例特点',tgt_zs)[0]\n",
    "    # print(out_zs,'|',tgt_zs)\n",
    "\n",
    "    hit = 0\n",
    "    tgt_num = 0\n",
    "    \n",
    "    times_zs = find_time(tgt_zs)\n",
    "    tgt_num += len(times_zs)\n",
    "    for t in times_zs:\n",
    "        if t in out_zs:\n",
    "            hit += 1\n",
    "\n",
    "    if '病程标准' in out:\n",
    "        out_bc = out.split('病程标准')[1].split('症状学标准')[0].replace('：','').replace(':','').replace('\\n','').replace('*','')\n",
    "        out_bc = re.split(r'\\d+\\.',re.split('症状学标准|症状标准|严重程度标准|严重标准|排除标准|排除诊断|病例特点',out_bc)[0])[0]\n",
    "    else:\n",
    "        try:\n",
    "            out_bc = re.split('病例特点|诊断标准|病程标准',out)[1]\n",
    "        except:\n",
    "            out_bc = ''\n",
    "    try:\n",
    "        tgt_bc = tgt.split('病程标准：')[1].split('2.')[0].replace('\\n','')\n",
    "    except:\n",
    "        tgt_bc = tgt.split('排除诊断')[0].split('病例特点')[1]\n",
    "    key_bc =  find_time(tgt_bc) + find_des(tgt_bc)\n",
    "    tgt_num += len(key_bc)\n",
    "    for k in key_bc:\n",
    "        if k in out_bc:\n",
    "            hit += 1\n",
    "    \n",
    "    if '严重程度标准' in out:\n",
    "        out_yz = re.split('严重程度标准|严重标准',out)[1].split('排除标准')[0].replace('：','').replace(':','').replace('\\n','').replace('*','')\n",
    "    else:\n",
    "        try:\n",
    "            out_yz = re.split('病例特点|诊断标准|病程标准',out)[1]\n",
    "        except:\n",
    "            out_yz = ''\n",
    "    try:\n",
    "        tgt_yz = re.split('严重程度标准：|严重标准',tgt)[1].split('4.')[0].replace('\\n','')\n",
    "    except:\n",
    "        tgt_yz = tgt.split('排除诊断')[0].split('病例特点')[1]\n",
    "    opt = ['严重','明显','轻微']\n",
    "    key_yz =  [o for o in opt if o in tgt_yz]\n",
    "    tgt_num += len(key_yz)\n",
    "    for k in key_yz:\n",
    "        if k in out_yz:\n",
    "            hit += 1\n",
    "\n",
    "    try:\n",
    "        acc = hit / tgt_num\n",
    "    except:\n",
    "        acc = 0\n",
    "        print(tgt)\n",
    "    return acc*100\n",
    "\n",
    "\n",
    "\n",
    "def acc_task2(out,tgt):\n",
    "    out_icd = find_icd(out.split('精神科共病诊断：')[0])\n",
    "    icd_dict = {}\n",
    "    with open('./data/psych/icd-10.jsonl','r',encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            data = json.loads(line)\n",
    "            icd_dict[data[\"ICD-10 Name\"]] = data['ICD-10 Code']\n",
    "    try:\n",
    "        tgt_name = re.split('精神科共病诊断：|鉴别诊断：',re.split('主要诊断：|明确诊断：',tgt)[1])[0].strip(' ').replace('\\n','').replace('。','').replace('，',',')\n",
    "        tgt_name = tgt_name.split(' ')[0]\n",
    "        tgt_icd = icd_dict[tgt_name]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # print(tgt)\n",
    "    \n",
    "    # print(out_icd,tgt_icd)\n",
    "    if len(out_icd) == 0:\n",
    "        # print(out)\n",
    "        acc = 0\n",
    "        return 0\n",
    "    acc = 0\n",
    "    if '.' in tgt_icd:\n",
    "        if out_icd[:3] == tgt_icd[:3]:\n",
    "            acc = 0.5\n",
    "        if out_icd == tgt_icd:\n",
    "            acc = 1\n",
    "    elif '-' in tgt_icd:\n",
    "        if int(out_icd[1:3]) > int(tgt_icd.split('-')[0][1:3]) and int(out_icd[1:3]) < int(tgt_icd.split('-')[1][1:3]):\n",
    "            acc = 1\n",
    "    else:\n",
    "        if int(out_icd[1:3]) == int(tgt_icd[1:3]):\n",
    "            acc = 1\n",
    "    # print(tgt_icd,'|',out_icd)\n",
    "    return acc*100\n",
    "\n",
    "### 修改为broad形式\n",
    "\n",
    "\n",
    "\n",
    "def refine_name(text):\n",
    "    names = ['人格障碍',\n",
    "            '双相情感障碍',\n",
    "            '器质性精神障碍',\n",
    "            '复发性抑郁障碍',\n",
    "            '妄想性障碍',\n",
    "            '广泛性焦虑障碍',\n",
    "            '强迫性障碍',\n",
    "            '心境障碍',\n",
    "            '急性而短暂的精神病性障碍',\n",
    "            '抑郁发作',\n",
    "            '抑郁障碍',\n",
    "            '焦虑障碍',\n",
    "            '环性心境',\n",
    "            '精神分裂症',\n",
    "            '精神障碍',\n",
    "            '脑器质性精神病',\n",
    "            '躁狂发作',\n",
    "            '躯体症状障碍',\n",
    "            '酒精所致的精神行为障碍',\n",
    "            '阿尔兹海默',\n",
    "            '阿尔茨海默']\n",
    "    for name in names:\n",
    "        if name in text:\n",
    "            return name\n",
    "    if len(re.findall(r'\\“(.*?)\\”',text)) > 0:\n",
    "        return re.findall(r'\\“(.*?)\\”',text)[0]\n",
    "    return text\n",
    "\n",
    "def refine_name_new(text):\n",
    "    text = text.replace('，',',')\n",
    "    names = []\n",
    "    with open('./data/psych/icd-10-broad.jsonl','r',encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            data = json.loads(line)\n",
    "            names.append(data[\"ICD-10 Name\"])\n",
    "    refined_name = ''\n",
    "    for name in names:\n",
    "        if name in text:\n",
    "            if len(name) > len(refined_name):\n",
    "                refined_name = name\n",
    "    if len(refined_name) > 0:        \n",
    "        return refined_name\n",
    "    if len(re.findall(r'\\“(.*?)\\”',text)) > 0:\n",
    "        return re.findall(r'\\“(.*?)\\”',text)[0]\n",
    "    return text\n",
    "\n",
    "\n",
    "def acc_task3_1(out,tgt):\n",
    "    \n",
    "    out = out.replace('：',':').replace(',','，')\n",
    "    try:\n",
    "        out_list = re.findall(r'\\[(.*?)\\]', out)\n",
    "        out_list = [out for out in out_list if out!= '疾病名称']\n",
    "        out_main = out_list[0]\n",
    "        out_dif1 = out_list[1]\n",
    "        out_dif2 = out_list[2]\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            out_main = out.split('主要诊断')[1].split('\\n')[0].replace('[','').replace(']','').replace(':','')\n",
    "            out_dif1 = out.split('<鉴别诊断1>')[1].split('\\n')[0].split('，')[0].replace('[','').replace(']','').replace(':','')\n",
    "            out_dif2 = out.split('<鉴别诊断2>')[1].split('\\n')[0].split('，')[0].replace('[','').replace(']','').replace(':','')\n",
    "        except:\n",
    "            try:\n",
    "                out_main_part = out.split('鉴别诊断:')[0]\n",
    "                out_main = refine_name(out_main_part)\n",
    "                if out_main == out_main_part:\n",
    "                    out_main = ''\n",
    "            except:\n",
    "                out_main = ''\n",
    "            try:\n",
    "                out_dif1 = out.split('<鉴别诊断1>')[1].split('<鉴别诊断2>')[0].split('鉴别点:')[0].replace('，','')\n",
    "            except:\n",
    "                \n",
    "                try:\n",
    "                    out_dif1 = out.split('鉴别诊断:')[1].split(':')[0].split('，')[0].replace('，','')\n",
    "                except:\n",
    "                    try:\n",
    "                        if '-' in out.split('鉴别诊断')[-1]:\n",
    "                            out_dif1 = out.split('鉴别诊断')[-1].split('-')\n",
    "                            if len(out_dif1) >= 3:\n",
    "                                out_dif1 = out_dif1[-2].split(':')[0].split('，')[0].replace('，','')\n",
    "                            else:\n",
    "                                out_dif1 = out_dif1[1].split(':')[0].split('，')[0].replace('，','')\n",
    "                        elif '1' in out.split('鉴别诊断')[-1]:\n",
    "                            out_dif1 = out.split('鉴别诊断')[-1].split('1')[-1].split(':')[0].split('，')[0].replace('，','')\n",
    "                        else:\n",
    "                            out_dif1 = out.split('鉴别诊断')[-1].split('，')[0].split(':')[-1]\n",
    "                    except:\n",
    "                        print(out)\n",
    "                        out_dif1 = ''\n",
    "            try:\n",
    "                out_dif2 = out.split('<鉴别诊断2>')[1].split('鉴别点:')[0].replace('，','')\n",
    "            except:\n",
    "                # print(out)\n",
    "                try:\n",
    "                    out_dif2 = out.split('鉴别诊断:')[1].split('2')[-1].split('-')[-1].split(':')[0].split('，')[0].replace('，','')\n",
    "                except:\n",
    "                    try:\n",
    "                        if '-' in out.split('鉴别诊断')[-1]:\n",
    "                            out_dif2 = out.split('鉴别诊断')[-1].split('-')\n",
    "                            if len(out_dif1) >= 3:\n",
    "                                out_dif2 = out_dif2[-1].split(':')[0].split('，')[0].replace('，','')\n",
    "                            else:\n",
    "                                out_dif2 = ''\n",
    "                        elif '2' in out.split('鉴别诊断')[-1]:\n",
    "                            out_dif2 = out.split('鉴别诊断')[-1].split('2')[-1].split(':')[0].split('，')[0].replace('，','')\n",
    "                        else:\n",
    "                            out_dif2 = out.split('鉴别诊断')[-1].replace('\\n\\n','\\n').split('\\n')[-1].split('，')[0].split(':')[-1]\n",
    "                    except:\n",
    "                        print(out)\n",
    "                        out_dif2 = ''\n",
    "\n",
    "    out_main = refine_name(out_main)\n",
    "    out_dif1 = refine_name(out_dif1)\n",
    "    out_dif2 = refine_name(out_dif2) \n",
    "    if fuzzy_match(out_main,tgt['main']):\n",
    "        acc_main = 1\n",
    "    else:\n",
    "        acc_main = 0\n",
    "    \n",
    "    acc_diff = 0\n",
    "    if fuzzy_match_list(out_dif1,tgt['diff']):\n",
    "        acc_diff += 0.5\n",
    "    if fuzzy_match_list(out_dif2,tgt['diff']):\n",
    "        acc_diff += 0.5\n",
    "    print(out_main,'|',out_dif1,'|',out_dif2)\n",
    "    return acc_main*100,acc_diff*100\n",
    "\n",
    "\n",
    "def find_icd_broad(text):\n",
    "    # text = \"患者的主要诊断是 F30.901，需要进行进一步的治疗。\"\n",
    "    icd_dict = {}\n",
    "    with open('./data/psych/icd-10-broad.jsonl','r',encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            data = json.loads(line)\n",
    "            icd_dict[data[\"ICD-10 Name\"]] = data['ICD-10 Code']\n",
    "    icd10_codes = re.findall(r'\\bF\\d+\\.*\\d+\\b', text)\n",
    "    refined_name = ''\n",
    "    if len(icd10_codes) < 1:\n",
    "        for name in icd_dict.keys():\n",
    "            if name in text:\n",
    "                if len(name) > len(refined_name):\n",
    "                    refined_name = name\n",
    "        if len(refined_name) > 0:\n",
    "            return icd_dict[refined_name]\n",
    "        # print('failed to find icd in:',text)\n",
    "        return ''\n",
    "    return icd10_codes[0]  # 输出: ['F30.901']\n",
    "\n",
    "def calc_icd_acc(out_icd,tgt_icd):\n",
    "    acc= 0\n",
    "    if len(out_icd) > 0 and len(tgt_icd) > 0:\n",
    "        if '-' not in out_icd and '-' not in tgt_icd:\n",
    "            if out_icd[1:3] == tgt_icd[1:3]:\n",
    "                acc = 1\n",
    "        elif '-' in out_icd and '-' not in tgt_icd:\n",
    "            if int(tgt_icd[1:3]) >= int(out_icd.split('-')[0][1:3]) and int(tgt_icd[1:3]) <= int(out_icd.split('-')[1][1:3]):\n",
    "                acc = 0.5\n",
    "            else:\n",
    "                acc = 0\n",
    "        elif '-' not in out_icd and '-' in tgt_icd:\n",
    "            if int(out_icd[1:3]) >= int(tgt_icd.split('-')[0][1:3]) and int(out_icd[1:3]) <= int(tgt_icd.split('-')[1][1:3]):\n",
    "                acc = 1\n",
    "            else:\n",
    "                acc = 0\n",
    "        elif '-' in out_icd and '-' in tgt_icd:\n",
    "            if out_icd == tgt_icd:\n",
    "                acc = 1\n",
    "            else:\n",
    "                acc = 0\n",
    "        else:\n",
    "            acc = 0\n",
    "    elif len(out_icd) == 0:\n",
    "        acc = 0\n",
    "    else:\n",
    "        acc = 1\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "def acc_task3_2(out,tgt):\n",
    "    out = out.replace('［','[').replace('］',']')\n",
    "    out = out.replace('：',':').replace(',','，').replace('[转换]','（转换）').replace('[情感]','(情感)')\n",
    "    try:\n",
    "        out_list = re.findall(r'\\[(.*?)\\]', out)\n",
    "        out_list = [out for out in out_list if '疾病名称' not in out]\n",
    "        out_main = out_list[0]\n",
    "        out_dif1 = out_list[1]\n",
    "        out_dif2 = out_list[2]\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            out_main = '主要诊断'.join(out.split('主要诊断')[1:]).split('鉴别诊断')[0].replace('[','').replace(']','').replace(':','')\n",
    "            out_dif1 = out.split('鉴别诊断1')[1].split('\\n')[0].split('，')[0].replace('[','').replace(']','').replace(':','')\n",
    "            out_dif2 = out.split('鉴别诊断2')[1].split('\\n')[0].split('，')[0].replace('[','').replace(']','').replace(':','')\n",
    "        except:\n",
    "            try:\n",
    "                # out_main_part = out.split('鉴别诊断:')[0]\n",
    "                out_main_part = re.split(r'鉴别诊断[0-9]?:', out)[0]\n",
    "                if '诊断:' in out_main_part:\n",
    "                    out_main_part = ''.join(out_main_part.split('诊断:')[1:])\n",
    "                out_main = refine_name_new(out_main_part)\n",
    "                if out_main == out_main_part:\n",
    "                    out_main = ''\n",
    "            except:\n",
    "                out_main = ''\n",
    "            try:\n",
    "                out_dif1 = out.split('<鉴别诊断1>')[1].split('<鉴别诊断2>')[0].split('鉴别点:')[0].replace('，','')\n",
    "            except:\n",
    "                \n",
    "                try:\n",
    "                    out_dif1 = out.split('鉴别诊断:')[1].split(':')[0].split('，')[0].replace('，','')\n",
    "                except:\n",
    "                    try:\n",
    "                        if '-' in out.split('鉴别诊断')[-1]:\n",
    "                            out_dif1 = out.split('鉴别诊断')[-1].split('-')\n",
    "                            if len(out_dif1) >= 3:\n",
    "                                out_dif1 = out_dif1[-2].split(':')[0].split('，')[0].replace('，','')\n",
    "                            else:\n",
    "                                out_dif1 = out_dif1[1].split(':')[0].split('，')[0].replace('，','')\n",
    "                        elif '1' in out.split('鉴别诊断')[-1]:\n",
    "                            out_dif1 = out.split('鉴别诊断')[-1].split('1')[-1].split(':')[0].split('，')[0].replace('，','')\n",
    "                        else:\n",
    "                            out_dif1 = out.split('鉴别诊断')[-1].split('，')[0].split(':')[-1]\n",
    "                    except:\n",
    "                        print(out)\n",
    "                        out_dif1 = ''\n",
    "            try:\n",
    "                out_dif2 = out.split('<鉴别诊断2>')[1].split('鉴别点:')[0].replace('，','')\n",
    "            except:\n",
    "                # print(out)\n",
    "                try:\n",
    "                    out_dif2 = out.split('鉴别诊断:')[1].split('2')[-1].split('-')[-1].split(':')[0].split('，')[0].replace('，','')\n",
    "                except:\n",
    "                    try:\n",
    "                        if '-' in out.split('鉴别诊断')[-1]:\n",
    "                            out_dif2 = out.split('鉴别诊断')[-1].split('-')\n",
    "                            if len(out_dif1) >= 3:\n",
    "                                out_dif2 = out_dif2[-1].split(':')[0].split('，')[0].replace('，','')\n",
    "                            else:\n",
    "                                out_dif2 = ''\n",
    "                        elif '2' in out.split('鉴别诊断')[-1]:\n",
    "                            out_dif2 = out.split('鉴别诊断')[-1].split('2')[-1].split(':')[0].split('，')[0].replace('，','')\n",
    "                        else:\n",
    "                            out_dif2 = out.split('鉴别诊断')[-1].replace('\\n\\n','\\n').split('\\n')[-1].split('，')[0].split(':')[-1]\n",
    "                    except:\n",
    "                        print(out)\n",
    "                        out_dif2 = ''\n",
    "\n",
    "    out_main = refine_name_new(out_main)\n",
    "    out_dif1 = refine_name_new(out_dif1)\n",
    "    out_dif2 = refine_name_new(out_dif2) \n",
    "    \n",
    "    ### 模糊匹配\n",
    "    if fuzzy_match(out_main,tgt['main']):\n",
    "        acc_main = 1\n",
    "    else:\n",
    "        acc_main = 0\n",
    "    \n",
    "    acc_diff = 0\n",
    "    if fuzzy_match_list(out_dif1,tgt['diff']):\n",
    "        acc_diff += 0.5\n",
    "    if fuzzy_match_list(out_dif2,tgt['diff']):\n",
    "        acc_diff += 0.5\n",
    "    # print(out_main,'|',out_dif1,'|',out_dif2)\n",
    "\n",
    "    ### ICD\n",
    "    out_main_icd = find_icd_broad(out_main)\n",
    "    out_dif1_icd = find_icd_broad(out_dif1)\n",
    "    out_dif2_icd = find_icd_broad(out_dif2)\n",
    "\n",
    "    tgt_main_icd = find_icd_broad(tgt['main'])\n",
    "    tgt_diffs_icd = [find_icd_broad(tgt_diff) for tgt_diff in tgt['diff']]\n",
    "\n",
    "    acc_main = calc_icd_acc(out_main_icd,tgt_main_icd)\n",
    "    \n",
    "    tgt_diffs_icd = [icd for icd in tgt_diffs_icd if len(icd)>0]\n",
    "    acc_diff = 0\n",
    "    if len(tgt_diffs_icd) > 1:\n",
    "        acc_diff += max(calc_icd_acc(out_dif1_icd,tgt_diffs_icd[0]),calc_icd_acc(out_dif1_icd,tgt_diffs_icd[1]))\n",
    "        acc_diff += max(calc_icd_acc(out_dif2_icd,tgt_diffs_icd[0]),calc_icd_acc(out_dif2_icd,tgt_diffs_icd[1]))\n",
    "        acc_diff = acc_diff/2\n",
    "    elif len(tgt_diffs_icd) == 1:\n",
    "        acc_diff += calc_icd_acc(out_dif1_icd,tgt_diffs_icd[0])\n",
    "        acc_diff += calc_icd_acc(out_dif2_icd,tgt_diffs_icd[0])\n",
    "    else:\n",
    "        print('couldn\\'t find tgt diff:',tgt['diff'])\n",
    "        acc_diff = 1\n",
    "    # print(out_main_icd,'|',out_dif1_icd,'|',out_dif2_icd)\n",
    "    # print(tgt_main_icd,'|',tgt_diffs_icd)\n",
    "    # print('='*20)\n",
    "\n",
    "    return acc_main*100,acc_diff*100\n",
    "\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def fuzzy_match(str1, str2):\n",
    "    \"\"\"\n",
    "    使用 Fuzzywuzzy 库进行模糊匹配，返回两个字符串之间的相似度百分比。\n",
    "    \"\"\"\n",
    "    ratio = fuzz.ratio(str1, str2)\n",
    "    \n",
    "    return ratio\n",
    "    \n",
    "def fuzzy_match_list(str1, tgt_list):\n",
    "    \"\"\"\n",
    "    使用 Fuzzywuzzy 库进行模糊匹配，返回两个字符串之间的相似度百分比。\n",
    "    \"\"\"\n",
    "    flag = False\n",
    "    ratio = 0\n",
    "    for str2 in tgt_list:\n",
    "        tmp_ratio = fuzzy_match(str1,str2)\n",
    "        if tmp_ratio > ratio:\n",
    "            ratio = tmp_ratio\n",
    "            # print(str2,ratio)\n",
    "    return ratio\n",
    "\n",
    "def hit_task4(out,tgt):\n",
    "    # drugs = ['丙戊酸', '伏硫西汀', '利培酮', '喹硫平', '奥氮平', '安非他酮', '帕利哌酮', '帕罗西汀', '度洛西汀', '拉莫三嗪', '文拉法辛', '氟伏沙明', '氟西汀', '米氮平', '舍曲林', '艾司西酞普兰', '西酞普兰', '阿戈美拉汀', '阿立哌唑', '马普替林', '齐拉西酮']\n",
    "    drugs = ['丙戊酸','伏硫西汀','利培酮', '安非他酮','劳拉西泮','唑吡坦','喹硫平','地西泮','奋乃静','奥氮平','奥沙西泮','帕利哌酮','帕罗西汀','度洛西汀','拉莫三嗪','文拉法辛','曲唑酮','氟伏沙明','氟哌啶醇','氟西汀','氨磺必利','氯丙嗪','氯氮平','硝西泮','碳酸锂','米氮平','美金刚','舍曲林','艾司西酞普兰','西酞普兰','阿戈美拉汀','阿立哌唑','鲁拉西酮','齐拉西酮']\n",
    "    out = out.replace('，',',').replace(' ','').replace('\\n\\n','\\n').replace('：',':')\n",
    "    tgt = tgt.replace('，',',').replace(' ','')\n",
    "    try:\n",
    "        if '推荐药物' in out:\n",
    "            out_chunks = '推荐药物'.join(out.split('推荐药物')[1:])\n",
    "        else:\n",
    "            out_chunks = out.split('\\n')\n",
    "            if len(out_chunks) == 1:\n",
    "                out_chunks = out_chunks\n",
    "            elif '分析' in out_chunks[0]:\n",
    "                out_chunks = out_chunks[1:]\n",
    "            # out_chunks = out.split('\\n')[1:]\n",
    "        \n",
    "        if isinstance(out_chunks,str):\n",
    "            out_chunks = [out_chunks]\n",
    "        ans_idx = 0\n",
    "        max_match = 0\n",
    "        for idx,piece in enumerate(out_chunks):\n",
    "            match = 0\n",
    "            for drug in drugs:\n",
    "                if drug in piece: match += 1\n",
    "            if match>max_match:\n",
    "                max_match = match\n",
    "                ans_idx = idx\n",
    "\n",
    "        # out_list = out_chunks[ans_idx].split(':')[-1].replace('。','') #.split(',')#.split('、')\n",
    "        out_list = []\n",
    "        for drug in drugs:\n",
    "            if drug in out_chunks[ans_idx]:\n",
    "                out_list.append(drug)\n",
    "        # 按照在答案中出现的顺序排序\n",
    "        out_list.sort(key=lambda x: out_chunks[ans_idx].find(x))\n",
    "    except:\n",
    "    #     out_list = out.split('分析')[0].split(',').split(' ')\n",
    "    \n",
    "    # if len(out_list[0]) > 6:\n",
    "        out_list = []\n",
    "        for drug in drugs:\n",
    "            if drug in '\\n'.join(out.split('推荐药物')[1:]):\n",
    "                out_list.append(drug)\n",
    "        out_list.sort(key=lambda x: ('\\n'.join(out.split('推荐药物')[1:])).find(x))\n",
    "    \n",
    "    if len(out_list) ==0:\n",
    "        out_list = []\n",
    "        for drug in drugs:\n",
    "            if drug in '\\n'.join(out.split('\\n')[1:]):\n",
    "                out_list.append(drug)\n",
    "        out_list.sort(key=lambda x: ('\\n'.join(out.split('\\n')[1:])).find(x))\n",
    "        \n",
    "    if len(out_list) ==0:  \n",
    "        out_list = ['']\n",
    "        # print('failed to match drug:',out)\n",
    "\n",
    "    \n",
    "    tgt_list = tgt.split(',')\n",
    "    \n",
    "    \n",
    "    o_in_t = [d for d in out_list if d in tgt_list]\n",
    "    t_in_o = [d for d in tgt_list if d in out_list]\n",
    "    acc = 0\n",
    "    if out_list[0]==tgt_list[0]:\n",
    "        acc = 1\n",
    "    recall = len(t_in_o) / len(tgt_list)\n",
    "    precision = len(o_in_t) / len(out_list)\n",
    "    \n",
    "    return acc*100,precision*100,recall*100\n",
    "\n",
    "def recall_task4(out,tgt):\n",
    "    # drugs = ['丙戊酸', '伏硫西汀', '利培酮', '喹硫平', '奥氮平', '安非他酮', '帕利哌酮', '帕罗西汀', '度洛西汀', '拉莫三嗪', '文拉法辛', '氟伏沙明', '氟西汀', '米氮平', '舍曲林', '艾司西酞普兰', '西酞普兰', '阿戈美拉汀', '阿立哌唑', '马普替林', '齐拉西酮']\n",
    "    drugs = ['丙戊酸','伏硫西汀','利培酮', '安非他酮','劳拉西泮','唑吡坦','喹硫平','地西泮','奋乃静','奥氮平','奥沙西泮','帕利哌酮','帕罗西汀','度洛西汀','拉莫三嗪','文拉法辛','曲唑酮','氟伏沙明','氟哌啶醇','氟西汀','氨磺必利','氯丙嗪','氯氮平','硝西泮','碳酸锂','米氮平','美金刚','舍曲林','艾司西酞普兰','西酞普兰','阿戈美拉汀','阿立哌唑','鲁拉西酮','齐拉西酮']\n",
    "    out = out.replace('，',',').replace(' ','').replace('\\n\\n','\\n').replace('：',':')\n",
    "    tgt = tgt.replace('，',',').replace(' ','')\n",
    "    \n",
    "    tgt_list = tgt.split(',')\n",
    "    hit_list = []\n",
    "    for tgt in tgt_list:\n",
    "        if tgt in out:\n",
    "            hit_list.append(tgt)\n",
    "    recall = len(hit_list) / len(tgt_list)\n",
    "    \n",
    "    return recall*100\n",
    "\n",
    "\n",
    "def task5_exam_acc(out,tgt):\n",
    "    correct = 0\n",
    "    ans = re.findall(r'[A-E]\\.', out)\n",
    "    if len(ans)<len(tgt):\n",
    "        ans = re.findall(r'[A-E]', out)\n",
    "        if len(ans)<len(tgt):\n",
    "            # print(out)\n",
    "            # print('-'*50)\n",
    "            if len(ans) < 1:\n",
    "                return 0\n",
    "            else:\n",
    "                for a,t in zip(ans,tgt[:len(ans)]):\n",
    "                    if a==t:\n",
    "                        correct += 1\n",
    "                return correct/len(tgt)*100\n",
    "    else:\n",
    "        ans = [a.replace('.','') for a in ans]\n",
    "\n",
    "    ans = ans[-len(tgt):]\n",
    "    \n",
    "    for a,t in zip(ans,tgt):\n",
    "        if a==t:\n",
    "            correct += 1\n",
    "    return correct/len(tgt)*100\n",
    "\n",
    "def task5_exam_acc_2(out,tgt):\n",
    "    tgt_options,tgt_contents = tgt\n",
    "    correct = 0\n",
    "    if '[' in out:\n",
    "        ans_list1 = out.split('[')[1:]\n",
    "    else:\n",
    "        ans_list1 = []\n",
    "    \n",
    "    out = out.replace('\\n\\n','\\n').strip(' ').strip('\\n')\n",
    "    ans_list2 = out.split('\\n')\n",
    "\n",
    "    if len(ans_list1) > len(ans_list2) or len(re.findall(r'\\[', out)) == len(tgt_options):\n",
    "        ans_list = ans_list1\n",
    "    else:\n",
    "        ans_list = ans_list2\n",
    "\n",
    "    if len(ans_list) > len(tgt_options):\n",
    "        ans_list = ans_list[-len(tgt_contents):]\n",
    "    # if len(ans_list) != len(tgt_options):\n",
    "    #     print(out)\n",
    "    #     print('='*50)\n",
    "\n",
    "    correct = 0\n",
    "    for t_opt,t_con,a in zip(tgt_options,tgt_contents,ans_list):\n",
    "        if len(re.findall(r'[A-Ea-e]', a)) > 0:\n",
    "            if t_opt == re.findall(r'[A-Ea-e]', a)[0].upper():\n",
    "                correct += 1\n",
    "                continue\n",
    "            if (t_con in a) or (a in t_con):\n",
    "                correct += 1\n",
    "                continue\n",
    "    return correct/len(tgt_options)*100\n",
    "\n",
    "\n",
    "def calc_ner_prf(ner_tgt,ner_out):\n",
    "    # ner_tgt = list(set(ner_tgt))\n",
    "    # ner_out = list(set(ner_out))\n",
    "\n",
    "    # intersection = len(set(ner_out).intersection(set(ner_tgt)))\n",
    "    # intersection_tgt = intersection\n",
    "    # intersection_out = intersection\n",
    "\n",
    "    intersection_tgt = 0\n",
    "    intersection_out = 0\n",
    "\n",
    "    for en in ner_tgt:\n",
    "        for en_ in ner_out:\n",
    "            if en in en_ or en_ in en or en==en_:\n",
    "                intersection_tgt += 1\n",
    "                break\n",
    "\n",
    "    for en in ner_out:\n",
    "        for en_ in ner_tgt:\n",
    "            if en in en_ or en_ in en or en==en_:\n",
    "                intersection_out += 1\n",
    "                break\n",
    "\n",
    "    # for en in ner_out:\n",
    "    #     if fuzzy_match_list(en,ner_tgt) > 80:\n",
    "    #         intersection += 1\n",
    "    # ner_tgt = list(set(ner_tgt))\n",
    "    # ner_out = list(set(ner_out))\n",
    "    precision = intersection_out / len(ner_out) if ner_out else 0\n",
    "    recall = intersection_tgt / len(ner_tgt) if ner_tgt else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return precision*100,recall*100,f1*100\n",
    "\n",
    "\n",
    "\n",
    "### calc\n",
    "\n",
    "nshot = NSHOT\n",
    "metrics_list = []   \n",
    "task3_ans = np.load('./data/psych/task3_ans.npy',allow_pickle=True).item()\n",
    "  \n",
    "for task in ['1','2','3','4','5_qa','5_mc']:\n",
    "    print('-'*100)\n",
    "    print('task',task)\n",
    "\n",
    "    for model in ['psychfound']: \n",
    "        if task == '5_exam' or task =='5': nshot = 0\n",
    "        ans_path = './result-refined/API/{}shot/task{}_{}.json'.format(nshot,task,model)\n",
    "        if task in ['1','3','5_qa']:\n",
    "            ner_path = './src/ner_result/PsychClinical/{}shot/{}/task{}/ner_result.npy'.format(nshot,model,task) #.replace('task3','task3-refined')\n",
    "            ner_result = np.load(ner_path,allow_pickle=True)\n",
    "            # print(ner_path,len(ner_result))\n",
    "        if not os.path.exists(ans_path):\n",
    "            print(ans_path,'not exist')\n",
    "            continue\n",
    "        # load data\n",
    "        lst_tgt = []\n",
    "        lst_out = []\n",
    "        lst_idx = []\n",
    "        lst_ipid = []\n",
    "        lst_tgt_option,lst_tgt_content = [],[]\n",
    "        option_qa = [[],[]]\n",
    "        with open(ans_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            answers = json.load(f)\n",
    "        idx = 0\n",
    "        for ans in answers:\n",
    "            if 'question_type' not in ans.keys():\n",
    "                ans['question_type'] = 'clinical'\n",
    "            if '选择题' in ans['question_type']:\n",
    "                option_qa[0].append(ans['answer'])\n",
    "                option_qa[1].append(ans['model_answer'])\n",
    "                idx += 1\n",
    "            else:\n",
    "                if ans['question_type'] == 'clinical':\n",
    "                    if task == '5_mc':\n",
    "                        lst_tgt_option.append(ans['answer'])\n",
    "                        tgt_content = ans['conversations'][1]['value'].split('\\n')\n",
    "                        tgt_content = ['.'.join(content.split('.')[1:]) for content in tgt_content]\n",
    "                        lst_tgt_content.append(tgt_content)\n",
    "                        lst_tgt.append([ans['answer'],tgt_content])\n",
    "                    elif ans['conversations'][1]['from']=='gpt':\n",
    "                        lst_tgt.append(ans['conversations'][1]['value'])\n",
    "                    else:\n",
    "                        lst_tgt.append(ans['conversations'][2]['value'])\n",
    "                else:\n",
    "                    lst_tgt.append(ans['answer'])\n",
    "                # lst_out.append(ans['model_answer'])\n",
    "                lst_out.append(ans['answer_0'])\n",
    "                lst_ipid.append(ans['id'])\n",
    "                lst_idx.append(idx)\n",
    "                idx += 1\n",
    "\n",
    "        # compute scores of each sample across entire dataset\n",
    "        scores_all = {}\n",
    "        failed = 0\n",
    "        # for tgt, out, idx in tqdm.tqdm(zip(lst_tgt, lst_out, lst_idx)):\n",
    "        for tgt, out, idx, ipid in zip(lst_tgt, lst_out, lst_idx,lst_ipid):\n",
    "\n",
    "            if out == 'API调用失败' or out == 'failed':\n",
    "                failed += 1\n",
    "                continue\n",
    "            # get sub-dict containing scores for each metric\n",
    "            # task1\n",
    "            if 'task1' in ans_path:\n",
    "                metrics = ['integrity','Acc']\n",
    "                # scores = [compute_integrity(out),acc_task1(out,tgt)]\n",
    "                try:\n",
    "                    scores = [compute_integrity(out),acc_task1(out,tgt)]\n",
    "                except Exception as e:\n",
    "                    print('Error!',e)\n",
    "                    print(ipid)\n",
    "                    print(out,tgt)\n",
    "\n",
    "            \n",
    "            # task2\n",
    "            if 'task2' in ans_path:\n",
    "                metrics = ['Acc']\n",
    "                scores = acc_task2(out,tgt)\n",
    "                # try:\n",
    "                #     scores = acc_task2(out,tgt)\n",
    "                # except Exception as e:\n",
    "                #     print(e)\n",
    "                #     print(ipid)\n",
    "                    # exit()\n",
    "            \n",
    "            # task3\n",
    "            if 'task3' in ans_path:\n",
    "                metrics = ['Acc_main','Acc_diff']\n",
    "                tgt = task3_ans[ipid]\n",
    "                # scores = acc_task3(out,tgt)\n",
    "                scores = acc_task3_2(out,tgt)\n",
    "                # try:\n",
    "                #     scores = acc_task3_2(out,tgt)\n",
    "                # except Exception as e:\n",
    "                #     print(e)\n",
    "                #     print(out)\n",
    "\n",
    "            \n",
    "            # task4\n",
    "            if 'task4' in ans_path:\n",
    "                metrics = ['Acc','precision','recall']\n",
    "                # print('-'*50)\n",
    "                # print(out)\n",
    "                scores = list(hit_task4(out,tgt))\n",
    "                # recall  = recall_task4(out,tgt)\n",
    "                # scores[-1] = recall\n",
    "\n",
    "\n",
    "            # task5 exam\n",
    "            if 'task5_mc' in ans_path:\n",
    "                metrics = ['Acc']\n",
    "                # print('-'*50)\n",
    "                # print(out)\n",
    "                scores = max(task5_exam_acc(out,tgt[0]),task5_exam_acc_2(out,tgt))\n",
    "\n",
    "            if 'task1' in ans_path or 'task3' in ans_path or 'task5' in ans_path:\n",
    "                if 'task5_mc' in ans_path:\n",
    "                    pass\n",
    "                else:\n",
    "                    if 'task5_qa' in ans_path:\n",
    "                        metrics = []\n",
    "                        scores = []\n",
    "                    ner_tgt,ner_out = ner_result[idx-failed]\n",
    "                    ner_scores = calc_ner_prf(ner_tgt,ner_out)\n",
    "                    if 'NER-Precision' not in metrics:\n",
    "                        metrics.extend(['NER-Precision','NER-Recall','NER-F1'])\n",
    "                    # metrics = list(set(metrics))\n",
    "                    scores = list(scores)\n",
    "                    scores.extend(ner_scores)\n",
    "                    # print(ner_scores)\n",
    "            # append to master dict, dataset object\n",
    "            scores_all[idx] = scores\n",
    "\n",
    "        # print(metrics)\n",
    "        print(model,np.mean(np.array(list(scores_all.values())),0),np.std(np.array(list(scores_all.values())),0))\n",
    "        avgs = np.mean(np.array(list(scores_all.values())),0,keepdims=False)\n",
    "        stds = np.std(np.array(list(scores_all.values())),0,keepdims=False)\n",
    "        if len(metrics) > 1:\n",
    "            for metric,avg,std in zip(metrics,avgs,stds):\n",
    "                metrics_list.append({'Task':'task{}'.format(task.replace('_mc','')),'Model': model, 'Metric': metric, 'Average': avg, 'Standard Deviation': std})\n",
    "        else:\n",
    "            metrics_list.append({'Task':'task{}'.format(task.replace('_mc','')),'Model': model, 'Metric': metrics[0], 'Average': avgs, 'Standard Deviation': stds})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "# 获取当前时间\n",
    "current_time = time.localtime()\n",
    "\n",
    "# 格式化日期和时间\n",
    "formatted_date_time = time.strftime(\"%Y%m%d-%H%M\", current_time)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def summarize_metrics_from_files(directory, file_pattern=\"metrics.json\",metrics_list=None,nshot=None):\n",
    "    # 初始化一个空的DataFrame来存储所有模型的指标\n",
    "    if 'ner_result' in directory:\n",
    "        file_pattern=\"metrics_new.json\" # calc with https://huggingface.co/iioSnail/bert-base-chinese-medical-ner \n",
    "    all_metrics = pd.DataFrame(columns=['Task','Model','Metric', 'Average', 'Standard Deviation'])\n",
    "    if metrics_list is None:\n",
    "        metrics_list = []\n",
    "    # 遍历指定目录\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == file_pattern:\n",
    "                # 构建完整的文件路径\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # 从文件中读取数据\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "\n",
    "                task = os.path.basename(root)\n",
    "                # if task == 'task5' or task == 'task3': continue\n",
    "                if task == 'task5_qa': continue\n",
    "                if task == 'task3-refined': continue\n",
    "\n",
    "                # 提取模型名（假设文件路径的最后一部分是模型名）\n",
    "                model_name = root.replace('\\\\','/').split('/')[-2].split('_')[0]\n",
    "                \n",
    "                # 提取指标并添加到DataFrame中\n",
    "                for metric, scores in data.items():\n",
    "                    if metric in ['NER-Precision','NER-Recall','NER-F1']: continue\n",
    "                    if metric in ['NER-score']: \n",
    "                        avg = scores['avg'] * 100\n",
    "                        std = scores['std'] * 100\n",
    "                    else:\n",
    "                        avg = scores['avg']\n",
    "                        std = scores['std']\n",
    "                    metrics_list.append({'Task':task.replace('-refined',''),'Model': model_name, 'Metric': metric, 'Average': avg, 'Standard Deviation': std})\n",
    "                    # metrics_list.append({'Task':task,'Model': model_name, 'Metric': metric, 'Average': avg, 'Standard Deviation': std})\n",
    "\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory.replace('1shot','0shot')):\n",
    "        for file in files:\n",
    "            if file == file_pattern:\n",
    "                # 构建完整的文件路径\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # 从文件中读取数据\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "\n",
    "                task = os.path.basename(root)\n",
    "                if task != 'task5_qa': continue\n",
    "                # 提取模型名（假设文件路径的最后一部分是模型名）\n",
    "                model_name = root.replace('\\\\','/').split('/')[-2].split('_')[0]\n",
    "                \n",
    "                # 提取指标并添加到DataFrame中\n",
    "                for metric, scores in data.items():\n",
    "                    if metric in ['NER-Precision','NER-Recall','NER-F1']: continue\n",
    "                    if metric in ['NER-score']: \n",
    "                        avg = scores['avg'] * 100\n",
    "                        std = scores['std'] * 100\n",
    "                    else:\n",
    "                        avg = scores['avg']\n",
    "                        std = scores['std']\n",
    "                    metrics_list.append({'Task':task.replace('-refined',''),'Model': model_name, 'Metric': metric, 'Average': avg, 'Standard Deviation': std})\n",
    "    \n",
    "    all_metrics = pd.concat([pd.DataFrame(metrics_list)], ignore_index=True)\n",
    "\n",
    "    # all_metrics.reset_index(drop=True, inplace=True)\n",
    "    os.makedirs('./result_table/',exist_ok=True)\n",
    "    all_metrics.to_csv('./result_table/summary_result_{}shot_{}.csv'.format(nshot,formatted_date_time), index=False)\n",
    "    print('saving result to ','./result_table/summary_result_{}shot_{}.csv'.format(nshot,formatted_date_time))\n",
    "    return all_metrics,metrics_list\n",
    "\n",
    "NSHOT = 0\n",
    "nshot = NSHOT\n",
    "# metrics_list = None\n",
    "\n",
    "# BLEU\\ROUGE\\BERTScore\n",
    "directory_path = \"./result/PsychClinical/{}shot\".format(nshot)\n",
    "summary_df,metrics_list = summarize_metrics_from_files(directory_path,metrics_list=metrics_list,nshot=nshot)\n",
    "# print(summary_df)\n",
    "\n",
    "# NER result\n",
    "directory_path = \"./src/ner_result/PsychClinical/{}shot\".format(nshot)\n",
    "summary_df,metrics_list = summarize_metrics_from_files(directory_path,metrics_list=metrics_list,nshot=nshot)\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded files\n",
    "table_df = pd.read_excel('./table_template.xlsx'.format(NSHOT))\n",
    "summary_result_df = pd.read_csv('./result_table/summary_result_{}shot_{}.csv'.format(NSHOT,formatted_date_time))\n",
    "\n",
    "# Display the first few rows of each dataframe to understand their structure\n",
    "table_df.head(), summary_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_map = {\n",
    "    'task1':{'BLEU':0,'ROUGE-L':1,'BERT':2,'integrity':3,'Acc':4,'NER-Precision':5,'NER-Recall':6,'NER-F1':7,'NER-score':8},\n",
    "    'task2':{'Acc':0},\n",
    "    'task3':{'BLEU':0,'ROUGE-L':1,'BERT':2,'Acc_main':3,'Acc_diff':4,'NER-Precision':5,'NER-Recall':6,'NER-F1':7,'NER-score':8},\n",
    "    'task4':{'Acc':0,'recall':1,'precision':2},\n",
    "    'task5':{'BLEU':0,'ROUGE-L':1,'BERT':2,'NER-Precision':3,'NER-Recall':4,'NER-F1':5,'NER-score':6,'Acc':7}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Function to format the data as 'avg±std' and round to 2 decimal places\n",
    "def format_data(avg, std):\n",
    "    return f\"{avg:.2f}±{std:.2f}\"\n",
    "\n",
    "# Update the matching logic to handle the differences in task names\n",
    "def get_column_name(task, metric):\n",
    "    # Handle special case for integrity metric\n",
    "    name =  col_name_map[task][metric]\n",
    "    if name == 0:\n",
    "        name = task \n",
    "    else:\n",
    "        name = f\"{task}.{name}\"\n",
    "    # Handle other metrics by appending the metric name with a dot separator\n",
    "    return name\n",
    "\n",
    "# Iterate over each row in summary_result_df and update the corresponding cells in table_df\n",
    "for index, row in summary_result_df.iterrows():\n",
    "    model = row['Model']\n",
    "    task = row['Task']  # Convert task1 to Task1 for matching\n",
    "    metric = row['Metric']\n",
    "    avg = row['Average']\n",
    "    std = row['Standard Deviation']\n",
    "    \n",
    "    # Find the column name in table_df that matches the task and metric\n",
    "    try:\n",
    "        column_name = get_column_name(task, metric)\n",
    "    except:\n",
    "        continue\n",
    "    if column_name in table_df.columns:\n",
    "        # Find the row in table_df that matches the model\n",
    "        model_row = table_df[table_df['model'] == model].index\n",
    "        if not model_row.empty:\n",
    "            # Update the cell with the formatted data\n",
    "            # if column_name =='task1.8' or column_name =='task3.8' or column_name =='task5.6': \n",
    "                # avg = avg * 100\n",
    "                # std = std * 100\n",
    "            table_df.at[model_row[0], column_name] = format_data(avg, std)\n",
    "\n",
    "table_df.to_excel('./result_table/table_new_{}shot_{}.xlsx'.format(NSHOT,formatted_date_time), index=False)\n",
    "\n",
    "print('Saving result to ','./result_table/table_new_{}shot_{}.xlsx'.format(NSHOT,formatted_date_time))\n",
    "# Display the updated table_df\n",
    "table_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knowledge test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calc knowledge test\n",
    "\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import os\n",
    "import json \n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "NSHOT = 0\n",
    "\n",
    "\n",
    "def task0_lt_acc(out,tgt):\n",
    "    tgt = [tgt]\n",
    "    correct = 0\n",
    "    ans = re.findall(r'[A-Ea-e]\\.', out)\n",
    "    # if len(ans) == 0:\n",
    "    #     ans = re.findall(r'[A-Z]', out)\n",
    "    if len(ans)<len(tgt):\n",
    "        ans = re.findall(r'[A-Ea-e]', out)\n",
    "        if len(ans)<len(tgt):\n",
    "            # print(out)\n",
    "            # print('-'*50)\n",
    "            if len(ans) < 1:\n",
    "                return 0\n",
    "            else:\n",
    "                for a,t in zip(ans,tgt[:len(ans)]):\n",
    "                    if a==t:\n",
    "                        correct += 1\n",
    "                return correct/len(tgt)*100\n",
    "    else:\n",
    "        ans = [a.replace('.','') for a in ans]\n",
    "\n",
    "    ans = ans[:len(tgt)]\n",
    "    \n",
    "    for a,t in zip(ans,tgt):\n",
    "        if a.upper()==t.upper():\n",
    "            correct += 1\n",
    "    return correct/len(tgt)*100\n",
    "\n",
    "\n",
    "def task0_lt_acc_2(out,tgt):\n",
    "    tgt_option,tgt_content = tgt\n",
    "    tgt_content = tgt_content.replace('，',',')\n",
    "    out = out.replace('，',',')\n",
    "    \n",
    "    out = out.replace('\\n\\n','\\n').strip(' ').strip('\\n')\n",
    "    \n",
    "\n",
    "    ## match option \n",
    "    if len(re.findall(r'[A-Ea-e]', out)) > 0:\n",
    "        if tgt_option == re.findall(r'[A-Ea-e]', out)[0].upper():\n",
    "            return 100\n",
    "    \n",
    "    ## match content\n",
    "    if (tgt_content in out) or (out in tgt_content):\n",
    "        return 100\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "### calc\n",
    "\n",
    "nshot = NSHOT\n",
    "metrics_list = []   \n",
    "knowledge_detailed = pd.DataFrame(columns=['Task', 'Model', 'id', 'acc'])\n",
    "\n",
    "def add_entry(task, model, ipid, scores, knowledge_detailed):\n",
    "    if len(knowledge_detailed) == 0:\n",
    "        knowledge_detailed = pd.DataFrame([{\n",
    "            'Task': f'{task.replace(\"_exam\", \"\")}',\n",
    "            'Model': model,\n",
    "            'id': ipid,\n",
    "            'acc': scores\n",
    "        }])\n",
    "    else:\n",
    "        existing_count = knowledge_detailed[(knowledge_detailed['Task']==task) & (knowledge_detailed['Model']==model)]['id'].str.startswith(ipid).sum()\n",
    "        if existing_count > 0:\n",
    "            new_ipid = f\"{ipid}-{existing_count}\"\n",
    "        else:\n",
    "            new_ipid = ipid\n",
    "        new_row = pd.DataFrame([{\n",
    "            'Task': f'{task.replace(\"_exam\", \"\")}',\n",
    "            'Model': model,\n",
    "            'id': new_ipid,\n",
    "            'acc': scores\n",
    "        }])\n",
    "        knowledge_detailed = pd.concat([knowledge_detailed, new_row], ignore_index=True)\n",
    "    return knowledge_detailed\n",
    "\n",
    "\n",
    "for task in ['0_mc_CMExam','0_knowledge','0_lt_split']:\n",
    "\n",
    "    print('-'*100)\n",
    "    print('task',task)\n",
    "    for model in ['psychfound']: \n",
    "\n",
    "        if task == '0_lt_split' or task == '0_knowledge' or task == '0_mc_CMExam': nshot = 0\n",
    "        ans_path = './result-refined/API/{}shot/task{}_{}.json'.format(nshot,task,model)\n",
    "        \n",
    "        if not os.path.exists(ans_path):\n",
    "            print(ans_path,'not exist')\n",
    "            continue\n",
    "        # load data\n",
    "        lst_tgt = []\n",
    "        lst_out = []\n",
    "        lst_idx = []\n",
    "        lst_ipid = []\n",
    "        lst_tgt_option,lst_tgt_content = [],[]\n",
    "        option_qa = [[],[]]\n",
    "        with open(ans_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            answers = json.load(f)\n",
    "        idx = 0\n",
    "        for ans in answers:\n",
    "            if 'question_type' not in ans.keys():\n",
    "                ans['question_type'] = 'clinical'\n",
    "            if '选择题' in ans['question_type']:\n",
    "                option_qa[0].append(ans['answer'])\n",
    "                option_qa[1].append(ans['model_answer'])\n",
    "                idx += 1\n",
    "            else:\n",
    "                if ans['question_type'] == 'clinical':\n",
    "                    if task == '0_lt_split' or task == '0_knowledge' or task=='0_mc_CMExam':\n",
    "                        lst_tgt_option.append(ans['answer'])\n",
    "                        tgt_content = '.'.join(ans['conversations'][1]['value'].split('.')[1:]) # drop A. B. etc in the beginning\n",
    "                        lst_tgt_content.append(tgt_content)\n",
    "                        lst_tgt.append([ans['answer'],tgt_content])\n",
    "                    elif ans['conversations'][1]['from']=='gpt':\n",
    "                        lst_tgt.append(ans['conversations'][1]['value'])\n",
    "                    else:\n",
    "                        lst_tgt.append(ans['conversations'][2]['value'])\n",
    "                else:\n",
    "                    lst_tgt.append(ans['answer'])\n",
    "                # lst_out.append(ans['model_answer'])\n",
    "                lst_out.append(ans['answer_0'])\n",
    "                lst_ipid.append(ans['id'])\n",
    "                lst_idx.append(idx)\n",
    "                idx += 1\n",
    "\n",
    "        # compute scores of each sample across entire dataset\n",
    "        scores_all = {}\n",
    "        failed = 0\n",
    "        # for tgt, out, idx in tqdm.tqdm(zip(lst_tgt, lst_out, lst_idx)):\n",
    "        for tgt, out, idx, ipid in zip(lst_tgt, lst_out, lst_idx,lst_ipid):\n",
    "\n",
    "            if out == 'API调用失败' or out == None:\n",
    "                failed += 1\n",
    "                continue\n",
    "            # get sub-dict containing scores for each metric\n",
    "            if '0_lt_split' in ans_path or '0_knowledge' in ans_path or '0_mc_CMExam' in ans_path:\n",
    "                metrics = ['Acc']\n",
    "                # print('-'*50)\n",
    "                # print(out)\n",
    "                # try:\n",
    "                #     scores = task0_lt_acc(out,tgt[0])\n",
    "                # except:\n",
    "                #     print(out)\n",
    "                scores = task0_lt_acc_2(out,tgt)\n",
    "                knowledge_detailed = add_entry('task{}'.format(task.replace('_exam','')),model,ipid,scores,knowledge_detailed)\n",
    "            scores_all[idx] = scores\n",
    "                \n",
    "        print(model.ljust(30),np.mean(np.array(list(scores_all.values())),0))\n",
    "        avgs = np.mean(np.array(list(scores_all.values())),0,keepdims=False)\n",
    "        stds = np.std(np.array(list(scores_all.values())),0,keepdims=False)\n",
    "        if len(metrics) > 1:\n",
    "            for metric,avg,std in zip(metrics,avgs,stds):\n",
    "                metrics_list.append({'Task':'task{}'.format(task.replace('_exam','')),'Model': model, 'Metric': metric, 'Average': avg, 'Standard Deviation': std})\n",
    "        else:\n",
    "            metrics_list.append({'Task':'task{}'.format(task.replace('_exam','')),'Model': model, 'Metric': metrics[0], 'Average': avgs, 'Standard Deviation': stds})\n",
    "\n",
    "import pandas as pd\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(metrics_list)\n",
    "df_detailed = pd.DataFrame(knowledge_detailed)\n",
    "print(len(df_detailed))\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "file_path = './result_table/knowledge_test_result.xlsx'\n",
    "df.to_excel(file_path, index=False)\n",
    "\n",
    "file_path = './result_table/knowledge_test_result_detailed.xlsx'\n",
    "df_detailed.to_excel(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
